[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft Computerlab",
    "section": "",
    "text": "Fr√ºhjahrssemester 2022"
  },
  {
    "objectID": "pages/admin/02_assessments.html",
    "href": "pages/admin/02_assessments.html",
    "title": "Leistungskontrollen",
    "section": "",
    "text": "Der Zweck dieser √úbungen ist, das Gelernte selber anzuwenden, oder dies zumindest zu versuchen. Es gibt f√ºr viele dieser √úbungen nicht eine definitive, richtige Antwort - es geht vor allem darum, es selber zu versuchen. Bei einzureichenden √úbungen gibt es die M√∂glichkeit, diese falls n√∂tig (nach Verbesserung) ein zweites Mal einzureichen.\nDie √úbungen sollen jeweils in dem entsprechenden Ordner auf ILIAS hochgeladen werden, und zwar in Form eines R Scripts, oder als Rmarkdown File.\nILIAS (Vormittag) üëâ 468703-FS2022-0\nILIAS (Nachmittag) üëâ 468703-FS2022-1\n\nEin gute Einf√ºhrung in Rmarkdown finden Sie z.B. hier.\n\nFalls mehrere Files abgegeben werden, sollte unbedingt alles in einem ZIP File komprimiert werden. Sie k√∂nnen auch eine Word/Libreoffice Datei abgeben; bitte f√ºgen Sie aber keinen R Code in ein Word Dokument ein.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis,\n  author = {Andrew Ellis},\n  title = {Leistungskontrollen},\n  url = {https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/admin/02_assessments.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. n.d. ‚ÄúLeistungskontrollen.‚Äù https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/admin/02_assessments.html."
  },
  {
    "objectID": "pages/admin/03_zulip_forum.html",
    "href": "pages/admin/03_zulip_forum.html",
    "title": "Zulip Forum",
    "section": "",
    "text": "Zulip ist besser geeignet, um Code darzustellen.\nWir benutzen dasselbe Forum f√ºr die Vormittags- und Nachmittagsveranstaltungen.\nDie Diskussion ist f√ºr alle Teilnehmer*innen sichtbar.\nDiskussion kann in Echtzeit (synchron) oder offline (asynchron) stattfinden.\n\nBitte erstellen Sie unter diesem Link einen Account. Sie m√ºssen daf√ºr Ihre Uni Emailadresse verwenden. Account erstellen üëâ zulipchat.com/join/hyuinbg3mtcumccnzt3tpsqb/\n Wenn Sie einen Account erstellt haben, k√∂nnen Sie sich unter folgendem Link einloggen. Zulip Forum üëâ neuroscicomplab2022.zulipchat.com\nAusserdem ist Zulip als Desktop oder Mobile App f√ºr alle g√§ngigen Betriebssysteme erh√§ltlich. Apps üëâ zulip.com/apps\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis,\n  author = {Andrew Ellis},\n  title = {Zulip {Forum}},\n  url = {https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/admin/03_zulip_forum.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. n.d. ‚ÄúZulip Forum.‚Äù https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/admin/03_zulip_forum.html."
  },
  {
    "objectID": "pages/admin/01_overview.html",
    "href": "pages/admin/01_overview.html",
    "title": "√úbersicht",
    "section": "",
    "text": "In diesem Kurs besch√§ftigen wir uns im weiteren Sinne mit Model-based Cognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht sehr lange, und ist aus dem Zusammenschluss von mathematischer Modellierung und neurowissenschaftlichen Methoden entstanden.\nWir widmen uns dem behavioralen/kognitiven Teil dieses Forschungsgebiets. Das bedeutet, wir analysieren Daten aus Verhaltensexperimenten ‚Äî sowohl mit herk√∂mmlichen statistischen Verfahren, als auch mit mathematischen Modellen. Die Resultate dieser Analysen k√∂nnen wiederum in der Analyse bildgebender Verfahren oder EEG benutzt werden.\n\nEs gibt ein sehr gutes Lehrbuch (Forstmann and Wagenmakers 2015) zum Thema Model-based Cognitive Neuroscience; wir werden einzelne Themen daraus aufgreifen. Das Buch ist auf SpringerLink verf√ºgbar: An Introduction to Model-Based Cognitive Neuroscience.\n\nWir werden folgende Themen im Laufe des Semester behandeln:\n\nErstellen von behavioralen Experimenten\nImportieren und Bearbeiten von Daten (z.B. bin√§re Daten, Reaktionszeiten)\nGraphische Darstellung und explorative Datenanalyse\nAuswahl von statistischen Verfahren\nEinf√ºhrung in die Bayesianische Datenanalyse\nAnalyse messwiederholter Daten anhand von Multilevel Modellen\nKognitive Prozessmodelle (mathematische Modelle von Entscheidungsverhalten)"
  },
  {
    "objectID": "pages/admin/01_overview.html#experimente",
    "href": "pages/admin/01_overview.html#experimente",
    "title": "√úbersicht",
    "section": "Experimente",
    "text": "Experimente\nUm ein Experiment zu kreieren benutzen wir PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen Benutzeroberfl√§che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/admin/01_overview.html#datenanalyse",
    "href": "pages/admin/01_overview.html#datenanalyse",
    "title": "√úbersicht",
    "section": "Datenanalyse",
    "text": "Datenanalyse\nUm Daten zu verarbeiten (data cleaning), grafisch darzustellen und zu analysieren werden wir R verwenden. Sie sollten daher die aktuelle Version von R installieren (Version 4.1.3), sowie RStudio.\nR üëâ https://cloud.r-project.org/\nRStudio üëâ https://www.rstudio.com/products/rstudio/download/#download\nF√ºr Bayesianische Datenanalyse verwenden wir ausserdem JASP und Stan. JASP ist ein GUI Programm, √§hnlich wie Jamovi, mit dem sich simple Bayesianische Tests durchf√ºhren lassen.\nJASP üëâ https://jasp-stats.org/download/\nStan ist eine probabilistische Programmiersprache, welche wir von R aus benutzen. Die daf√ºr ben√∂tigte Software werden wir im Verlauf des Semesters installieren."
  },
  {
    "objectID": "pages/chapters/03_data_cleaning.html",
    "href": "pages/chapters/03_data_cleaning.html",
    "title": "Data cleaning",
    "section": "",
    "text": "Note\n\n\n\nüëâ R Code f√ºr dieses Kapitel downloaden"
  },
  {
    "objectID": "pages/chapters/03_data_cleaning.html#reaktionszeiten",
    "href": "pages/chapters/03_data_cleaning.html#reaktionszeiten",
    "title": "Data cleaning",
    "section": "Reaktionszeiten",
    "text": "Reaktionszeiten\nDrei h√§ufig verwendete Tasks, um Reaktionszeiten zu messen sind\n\nReaction tasks\nGo/No Go tasks\nDiscrimination tasks\n\nBei Reaction tasks muss auf einen Reiz reagiert werden, bei Go/No Go tasks muss zwischen zwei Reizen unterschieden, und nur auf einen reagiert werden. Discrimination tasks erfordern komplexere kognitive Leistungen, da eine von zwei Antworten gegeben werden muss, in Abh√§ngigkeit des Reizes.\nWenn wir Reaktionszeiten messen, gehen wir gehen davon aus, dass die Zeit, die ben√∂tigt wird, um einen Task auszuf√ºhren, uns √ºber den kognitiven Prozess Auskunft gibt. Dabei ist es aber wichtig, dass die Versuchsperson in dieser Zeit wirklich genau den Task ausf√ºhrt, und nicht nebenher noch andere Prozesse die Reaktionszeit beeinflussen, da diese sonst bedeutungslos w√§re. Leider ist dies nicht immer der Fall. Bei vielen repetitiven Tasks sind attentional lapses nicht zu vermeiden, und nur bei den einfachsten Tasks ist es m√∂glich, sicherzustellen, dass die VP auch wirklich den intendierten Task ausf√ºhrt."
  },
  {
    "objectID": "pages/chapters/03_data_cleaning.html#eigenschaften-von-reaktionszeiten",
    "href": "pages/chapters/03_data_cleaning.html#eigenschaften-von-reaktionszeiten",
    "title": "Data cleaning",
    "section": "Eigenschaften von Reaktionszeiten",
    "text": "Eigenschaften von Reaktionszeiten\nDie wichtigsten Merkmale von Reaktionszeiten sind\n\nSie sind rechtsschief\nSie sind nicht normalverteilt\nStreuung (Standardabweichung) steigt ungef√§hr linear mit wachsendem Mittelwert (Wagenmakers and Brown 2007)\n\nDie Rechtschiefe ist eine nat√ºrliche Konsequenz der Tatsache, dass es viele M√∂glichkeiten gibt, langsamer zu werden, aber nur wenige M√∂glichkeiten, schneller zu werden. Reaktionszeiten k√∂nnen nicht negativ sein Ausserdem gibt es eine Untergrenze, welche durch unsere Physiologie bestimmt ist. Schellere Reaktionszeiten als 200 Millisekunden sind kaum m√∂glich.\nDie Konsequenz daraus ist, dass Reaktionszeiten nicht normalverteilt sind. In folgender Grafik sind zwei Verteilungen dargestellt. Die gelbe Verteilung ist eine Normalverteilung mit \\(\\mu = 1\\) und \\(\\sigma = 0.4\\), w√§hrend die graue Verteilung eine LogNormal Verteilung darstellt.\n\nEine LogNormal-Verteilung bedeutet, dass der Logarithmus einer Zufallsvariablen normalverteilt ist.\n\n\n\n\n\n\nObwohl die Normalverteilung so aussieht, als k√∂nne sie Reaktionszeiten repr√§sentieren, ist der Wertebereich von \\([-\\Inf, \\Inf]\\) nicht daf√ºr geeignet. Ausserdem erlaubt die Normalverteilung keine extremen Werte, und ist nicht asymmetrisch."
  },
  {
    "objectID": "pages/chapters/03_data_cleaning.html#daten-aus-einem-reaktionszeitexperiment",
    "href": "pages/chapters/03_data_cleaning.html#daten-aus-einem-reaktionszeitexperiment",
    "title": "Data cleaning",
    "section": "Daten aus einem Reaktionszeitexperiment",
    "text": "Daten aus einem Reaktionszeitexperiment\nWir untersuchen nun Daten aus einem Online-Experiement mit 3 Bl√∂cken. In jedem Block mussten Versuchspersonen einen anderen Task ausf√ºhren. Unser Ziel ist es, Datenpunkte zu identfizieren, welche wir eventuell ausschliessen m√ºssen.\nDie drei Tasks sind:\n\nReaction task\n\nVersuchspersonen dr√ºcken SPACE-Taste wenn ein Stimulus erscheint (Quadrat oder Kreis). Abh√§ngige Variable ist die Reaktionszeit.\n\nGo/No-Go task\n\nVersuchspersonen dr√ºcken SPACE-Taste wenn Target erscheint (entweder Quadrat oder Kreis). Abh√§ngige Variablen sind Reaktionszeit und Antwort.\n\nDiscrimination task\n\nVersuchspersonen dr√ºcken F-Taste wenn ein Quadrat erscheint, J-Taste wenn ein Kreis erscheint. Abh√§ngige Variablen sind Reaktionszeit und Antwort.\nAnnahme: Versuchspersonen brauchen im Reaction Task am wenigsten Zeit, um eine korrekte Antwort zu geben, gefolgt vom Go/No-Go Task. Im Discrimination Task brauchen Versuchspersonen l√§nger, um korrekte Antworten zu geben.\n\nlibrary(tidyverse)\n\nURL <- \"https://raw.githubusercontent.com/kogpsy/neuroscicomplab/main/data/mental-chronometry.csv\"\n\nmentalchronometry <- read_csv(URL) |> \n  mutate(across(c(subj, block, stimulus, handedness, gender), ~as_factor(.)))\n\nRows: 2519 Columns: 7\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (4): block, stimulus, handedness, gender\ndbl (3): subj, trial_number, RT\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(mentalchronometry)\n\nRows: 2,519\nColumns: 7\n$ subj         <fct> 8554, 8554, 8554, 8554, 8554, 8554, 8554, 8554, 8554, 855‚Ä¶\n$ trial_number <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ block        <fct> reaction, reaction, reaction, reaction, reaction, reactio‚Ä¶\n$ stimulus     <fct> circle, square, square, square, circle, square, square, c‚Ä¶\n$ RT           <dbl> 311, 269, 317, 325, 240, 262, 295, 277, 288, 309, 319, 29‚Ä¶\n$ handedness   <fct> Right, Right, Right, Right, Right, Right, Right, Right, R‚Ä¶\n$ gender       <fct> female, female, female, female, female, female, female, f‚Ä¶\n\n\n\nmentalchronometry\n\n# A tibble: 2,519 √ó 7\n   subj  trial_number block    stimulus    RT handedness gender\n   <fct>        <dbl> <fct>    <fct>    <dbl> <fct>      <fct> \n 1 8554             1 reaction circle     311 Right      female\n 2 8554             2 reaction square     269 Right      female\n 3 8554             3 reaction square     317 Right      female\n 4 8554             4 reaction square     325 Right      female\n 5 8554             5 reaction circle     240 Right      female\n 6 8554             6 reaction square     262 Right      female\n 7 8554             7 reaction square     295 Right      female\n 8 8554             8 reaction circle     277 Right      female\n 9 8554             9 reaction square     288 Right      female\n10 8554            10 reaction circle     309 Right      female\n# ‚Ä¶ with 2,509 more rows\n\n\nHier sind die Daten von 5 zuf√§llig ausgew√§hlten Personen:\n\nset.seed(98)\nsubjects <- sample(levels(mentalchronometry$subj), 6)\ndf <- mentalchronometry |>\n  filter(subj %in% subjects)\n\ndf |> \n  ggplot(aes(RT, fill = block)) +\n  geom_histogram(alpha = 0.8, position = \"identity\", color = \"black\") +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  facet_grid(block ~ subj, scales = \"free_x\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\ndf |> \n  filter(subj %in% subjects) |> \n  ggplot(aes(y = RT, x = block, fill = block)) +\n  geom_violin(alpha = 0.6) +\n  geom_jitter(width = 0.1) +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  facet_wrap(~ subj, scales = \"free_x\") +\n  theme(legend.position = \"none\")\n\n\n\n\nWir k√∂nnen versuchen Ausreisser zu identifizieren."
  },
  {
    "objectID": "pages/chapters/03_data_cleaning.html#cleaning-by-subject",
    "href": "pages/chapters/03_data_cleaning.html#cleaning-by-subject",
    "title": "Data cleaning",
    "section": "Cleaning by subject",
    "text": "Cleaning by subject\nUnser Ziel ist es, die Daten einer Versuchsperson zu entfernen, falls diese Person in einer experimentellen Bedingung eine mittlere RT hat, welche mehr als 2 Standardabweichungen vom Gesamtmittelwert liegt.\n\n# summary stats (means) for participants\nsum_stats_participants <- mentalchronometry |> \n  group_by(subj, block) |> \n  dplyr::summarise(\n    mean_P = mean(RT))\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions <- mentalchronometry |> \n  group_by(block) |> \n  dplyr::summarise(\n    mean_C = mean(RT),\n    sd_C = sd(RT))\n  \nsum_stats_participants <- \n  full_join(\n    sum_stats_participants,\n    sum_stats_conditions,\n    by = \"block\") |> \n  mutate(\n    outlier_P = abs(mean_P - mean_C) > 2 * sd_C)\n\n# show outlier participants\nsum_stats_participants |> \n  filter(outlier_P == 1) |> \n  show()\n\n# A tibble: 1 √ó 6\n# Groups:   subj [1]\n  subj  block          mean_P mean_C  sd_C outlier_P\n  <fct> <fct>           <dbl>  <dbl> <dbl> <lgl>    \n1 8505  discrimination  1078.   518.  185. TRUE     \n\n\nWir haben also eine Person, welche in einer Bedingung (discrimination) eine mittlere RT hat, welche mehr als 2 Standardabweichungen vom Gesamtmittelwert dieser Bedingung liegt.\nWeiter k√∂nnen wir die RT f√ºr jeden Trial in jeder Bedingung plotten. Es ist klar, dass die mittlere RT im discrimination aufgrund mehrerer Ausreisser zustande kommt.\n\nmentalchronometry |> \n  semi_join(sum_stats_participants |> filter(outlier_P == 1), \n    by = c(\"subj\")) |> \n  ggplot(aes(x = trial_number, y = RT)) +\n  geom_point() +\n  facet_wrap(~block)\n\n\n\n\nWir k√∂nnten diese Person ganz ausschliessen.\n\nexcluded <- sum_stats_participants |> \n  filter(outlier_P == 1)\n\nexcluded\n\n# A tibble: 1 √ó 6\n# Groups:   subj [1]\n  subj  block          mean_P mean_C  sd_C outlier_P\n  <fct> <fct>           <dbl>  <dbl> <dbl> <lgl>    \n1 8505  discrimination  1078.   518.  185. TRUE     \n\n\n\nmentalchronometry_cleaned <- mentalchronometry |> \n  filter(!(subj %in% excluded$subj)) |> \n  mutate(subj = fct_drop(subj))"
  },
  {
    "objectID": "pages/chapters/03_data_cleaning.html#cleaning-by-trial",
    "href": "pages/chapters/03_data_cleaning.html#cleaning-by-trial",
    "title": "Data cleaning",
    "section": "Cleaning by trial",
    "text": "Cleaning by trial\nNun wollen alle Trials identifizieren, welche mehr als 2 Standardabweichungen vom Bedingungs-Gesamtmittelwert liegen. Ausserdem entfernen wir alle RTs, welche unter 100 Millisekunden liegen.\n\n# mark individual trials as outliers\nmentalchronometry_cleaned <- mentalchronometry_cleaned |> \n  full_join(\n    sum_stats_conditions,\n    by = \"block\") |> \n  mutate(\n    trial_type = case_when(\n      abs(RT - mean_C) > 2 * sd_C ~ \"zu weit vom Mittelwert\",\n      RT < 100 ~ \"< 100ms\",\n      TRUE ~ \"OK\") |> \n      factor(levels = c(\"OK\", \"< 100ms\", \"zu weit vom Mittelwert\")),\n    trial = row_number())\n\n\n# visualize outlier trials\nmentalchronometry_cleaned |> \n  ggplot(aes(x = trial, y = RT, color = trial_type, shape = trial_type)) +\n  geom_point(alpha = 0.6) + \n  geom_point(data = filter(mentalchronometry_cleaned, trial_type != \"OK\"), \n             alpha = 0.9) + \n  facet_grid(~block) +\n  scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\n\n\nWir haben insgesamt 63 Trials, welche nach unseren Kriterien Ausreisser sein k√∂nnten.\n\nmentalchronometry_cleaned |> \n  filter(trial_type != \"OK\")\n\n# A tibble: 63 √ó 11\n   subj  trial_number block    stimulus    RT handedness  gender mean_C  sd_C\n   <fct>        <dbl> <fct>    <fct>    <dbl> <fct>       <fct>   <dbl> <dbl>\n 1 8552            11 goNoGo   square     690 Right       male     442.  104.\n 2 8552            14 goNoGo   square     727 Right       male     442.  104.\n 3 8552            17 goNoGo   square     697 Right       male     442.  104.\n 4 8552            18 goNoGo   square     720 Right       male     442.  104.\n 5 8551             3 reaction square     712 right       male     311.  157.\n 6 8550            16 reaction square      54 right       male     311.  157.\n 7 8550             4 goNoGo   circle    1010 right       male     442.  104.\n 8 8549            11 reaction square    2244 Righthanded male     311.  157.\n 9 8549            20 reaction square    1087 Righthanded male     311.  157.\n10 8549            12 goNoGo   square     778 Righthanded male     442.  104.\n# ‚Ä¶ with 53 more rows, and 2 more variables: trial_type <fct>, trial <int>\n\n\nDiese 63 Trials entfernen wir nun.\n\nmentalchronometry_cleaned <- mentalchronometry_cleaned |> \n  filter(trial_type == \"OK\")\n\n\nmentalchronometry_cleaned |> \n  ggplot(aes(x = RT, color = block, fill = block)) +\n  geom_density(alpha = 0.3) +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  scale_color_viridis(discrete=TRUE, option=\"cividis\")\n\n\n\n\nData Cleaning ist zwar in den meisten F√§llen notwendig, aber leider etwas willk√ºrlich, und gibt dem Forscher/der Forscherin sehr viele Freiheiten (researcher degrees of freedom). Es ist deshlab wichtig, Ausschlusskriterien f√ºr Personen und einzelne Trials vor der Analyse festzulegen, und offen zu berichten."
  }
]