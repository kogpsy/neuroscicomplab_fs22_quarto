[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neurowissenschaft Computerlab",
    "section": "",
    "text": "Fr√ºhjahrssemester 2022"
  },
  {
    "objectID": "pages/solutions/solution_03.html",
    "href": "pages/solutions/solution_03.html",
    "title": "√úbung 3: L√∂sung",
    "section": "",
    "text": "Reusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis2022,\n  author = {Andrew Ellis},\n  title = {√úbung 3: {L√∂sung}},\n  date = {04/03/2022},\n  url = {https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/solutions/solution_03.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. 4AD‚Äì3AD. ‚Äú√úbung 3: L√∂sung.‚Äù 4AD‚Äì3AD. https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/solutions/solution_03.html."
  },
  {
    "objectID": "pages/admin/02_assessments.html",
    "href": "pages/admin/02_assessments.html",
    "title": "Leistungskontrollen",
    "section": "",
    "text": "Der Zweck dieser √úbungen ist, das Gelernte selber anzuwenden, oder dies zumindest zu versuchen. Es gibt f√ºr viele dieser √úbungen nicht eine definitive, richtige Antwort - es geht vor allem darum, es selber zu versuchen. Bei einzureichenden √úbungen gibt es die M√∂glichkeit, diese falls n√∂tig (nach Verbesserung) ein zweites Mal einzureichen.\nDie √úbungen sollen jeweils in dem entsprechenden Ordner auf ILIAS hochgeladen werden, und zwar in Form eines R Scripts, oder als Rmarkdown File.\nILIAS (Vormittag) üëâ 468703-FS2022-0\nILIAS (Nachmittag) üëâ 468703-FS2022-1\n\nEin gute Einf√ºhrung in Rmarkdown finden Sie z.B. hier.\n\nFalls mehrere Files abgegeben werden, sollte unbedingt alles in einem ZIP File komprimiert werden. Sie k√∂nnen auch eine Word/Libreoffice Datei abgeben; bitte f√ºgen Sie aber keinen R Code in ein Word Dokument ein.\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis,\n  author = {Andrew Ellis},\n  title = {Leistungskontrollen},\n  url = {https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/admin/02_assessments.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. n.d. ‚ÄúLeistungskontrollen.‚Äù https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/admin/02_assessments.html."
  },
  {
    "objectID": "pages/admin/03_zulip_forum.html",
    "href": "pages/admin/03_zulip_forum.html",
    "title": "Zulip Forum",
    "section": "",
    "text": "Zulip ist besser geeignet, um Code darzustellen.\nWir benutzen dasselbe Forum f√ºr die Vormittags- und Nachmittagsveranstaltungen.\nDie Diskussion ist f√ºr alle Teilnehmer*innen sichtbar.\nDiskussion kann in Echtzeit (synchron) oder offline (asynchron) stattfinden.\n\nBitte erstellen Sie unter diesem Link einen Account. Sie m√ºssen daf√ºr Ihre Uni Emailadresse verwenden. Account erstellen üëâ zulipchat.com/join/hyuinbg3mtcumccnzt3tpsqb/\n Wenn Sie einen Account erstellt haben, k√∂nnen Sie sich unter folgendem Link einloggen. Zulip Forum üëâ neuroscicomplab2022.zulipchat.com\nAusserdem ist Zulip als Desktop oder Mobile App f√ºr alle g√§ngigen Betriebssysteme erh√§ltlich. Apps üëâ zulip.com/apps\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis,\n  author = {Andrew Ellis},\n  title = {Zulip {Forum}},\n  url = {https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/admin/03_zulip_forum.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. n.d. ‚ÄúZulip Forum.‚Äù https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/admin/03_zulip_forum.html."
  },
  {
    "objectID": "pages/admin/01_overview.html",
    "href": "pages/admin/01_overview.html",
    "title": "√úbersicht",
    "section": "",
    "text": "In diesem Kurs besch√§ftigen wir uns im weiteren Sinne mit Model-based Cognitive Neuroscience. Dieses Forschungsgebiet existiert noch nicht sehr lange, und ist aus dem Zusammenschluss von mathematischer Modellierung und neurowissenschaftlichen Methoden entstanden.\nWir widmen uns dem behavioralen/kognitiven Teil dieses Forschungsgebiets. Das bedeutet, wir analysieren Daten aus Verhaltensexperimenten ‚Äî sowohl mit herk√∂mmlichen statistischen Verfahren, als auch mit mathematischen Modellen. Die Resultate dieser Analysen k√∂nnen wiederum in der Analyse bildgebender Verfahren oder EEG benutzt werden.\n\nEs gibt ein sehr gutes Lehrbuch (Forstmann and Wagenmakers 2015) zum Thema Model-based Cognitive Neuroscience; wir werden einzelne Themen daraus aufgreifen. Das Buch ist auf SpringerLink verf√ºgbar: An Introduction to Model-Based Cognitive Neuroscience.\n\nWir werden folgende Themen im Laufe des Semester behandeln:\n\nErstellen von behavioralen Experimenten\nImportieren und Bearbeiten von Daten (z.B. bin√§re Daten, Reaktionszeiten)\nGraphische Darstellung und explorative Datenanalyse\nAuswahl von statistischen Verfahren\nEinf√ºhrung in die Bayesianische Datenanalyse\nAnalyse messwiederholter Daten anhand von Multilevel Modellen\nKognitive Prozessmodelle (mathematische Modelle von Entscheidungsverhalten)"
  },
  {
    "objectID": "pages/admin/01_overview.html#experimente",
    "href": "pages/admin/01_overview.html#experimente",
    "title": "√úbersicht",
    "section": "Experimente",
    "text": "Experimente\nUm ein Experiment zu kreieren benutzen wir PsychoPy. PsychoPy ist ein Python-basiertes Tool, mit dem sich sowohl in einer grafischen Benutzeroberfl√§che (GUI) als auch mit Python Code Experimente programmieren lassen."
  },
  {
    "objectID": "pages/admin/01_overview.html#datenanalyse",
    "href": "pages/admin/01_overview.html#datenanalyse",
    "title": "√úbersicht",
    "section": "Datenanalyse",
    "text": "Datenanalyse\nUm Daten zu verarbeiten (data cleaning), grafisch darzustellen und zu analysieren werden wir R verwenden. Sie sollten daher die aktuelle Version von R installieren (Version 4.1.3), sowie RStudio.\nR üëâ https://cloud.r-project.org/\nRStudio üëâ https://www.rstudio.com/products/rstudio/download/#download\nF√ºr Bayesianische Datenanalyse verwenden wir ausserdem JASP und Stan. JASP ist ein GUI Programm, √§hnlich wie Jamovi, mit dem sich simple Bayesianische Tests durchf√ºhren lassen.\nJASP üëâ https://jasp-stats.org/download/\nStan ist eine probabilistische Programmiersprache, welche wir von R aus benutzen. Die daf√ºr ben√∂tigte Software werden wir im Verlauf des Semesters installieren."
  },
  {
    "objectID": "pages/chapters/02_importing_data.html",
    "href": "pages/chapters/02_importing_data.html",
    "title": "Daten importieren",
    "section": "",
    "text": "Nun wollen wir die Datens√§tze aus dem Verhaltensexperiment von der letzten Sitzung in R importieren.\nLaden Sie das RStudio Projekt und √∂ffnen Sie es. Im Projekt ist ein R Script File enthalten (import-data.R).\n\nFalls Sie nur den R Code m√∂chten, k√∂nnen Sie das File hier downloaden: üëâ R Code"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#csv-file-importieren",
    "href": "pages/chapters/02_importing_data.html#csv-file-importieren",
    "title": "Daten importieren",
    "section": "CSV File importieren",
    "text": "CSV File importieren\n\ntestdata <- read_csv(\"testdata/ZZ_rdk-discrimination_2022_Mar_07_1403.csv\") \n\nVariablen √ºberpr√ºfen\n\nglimpse(testdata)\n\nRows: 167\nColumns: 39\n$ cue                                        <chr> \"none\", \"left\", \"right\", \"l‚Ä¶\n$ direction                                  <chr> \"right\", \"right\", \"right\", ‚Ä¶\n$ practice_block_loop.thisRepN               <dbl> 0, 0, 0, 0, 0, 0, NA, NA, N‚Ä¶\n$ practice_block_loop.thisTrialN             <dbl> 0, 1, 2, 3, 4, 5, NA, NA, N‚Ä¶\n$ practice_block_loop.thisN                  <dbl> 0, 1, 2, 3, 4, 5, NA, NA, N‚Ä¶\n$ practice_block_loop.thisIndex              <dbl> 5, 2, 1, 0, 4, 3, NA, NA, N‚Ä¶\n$ main_blocks_loop.thisRepN                  <dbl> NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ main_blocks_loop.thisTrialN                <dbl> NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ main_blocks_loop.thisN                     <dbl> NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ main_blocks_loop.thisIndex                 <dbl> NA, NA, NA, NA, NA, NA, NA,‚Ä¶\n$ static_isi.started                         <dbl> 0.01033428, 0.03202713, 0.0‚Ä¶\n$ static_isi.stopped                         <dbl> 2.010334, 2.032027, 2.03217‚Ä¶\n$ fixation_pre.started                       <dbl> 26.79425, 36.16522, 44.7852‚Ä¶\n$ fixation_pre.stopped                       <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ image.started                              <dbl> 27.19849, 36.28205, 46.0032‚Ä¶\n$ image.stopped                              <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ fixation_post.started                      <dbl> 28.17814, 37.28240, 47.0037‚Ä¶\n$ fixation_post.stopped                      <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_background.started                    <dbl> 32.18642, 41.30145, 52.0107‚Ä¶\n$ dots_background.stopped                    <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_stimulus.started                      <dbl> 32.18642, 41.30145, 52.0107‚Ä¶\n$ dots_stimulus.stopped                      <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_keyboard_response.keys                <chr> \"None\", \"f\", \"j\", \"f\", \"Non‚Ä¶\n$ dots_keyboard_response.started             <dbl> 32.18642, 41.30145, 52.0107‚Ä¶\n$ dots_keyboard_response.stopped             <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ feedback_text.started                      <dbl> 33.70200, 42.28899, 52.9229‚Ä¶\n$ feedback_text.stopped                      <chr> \"None\", \"None\", \"None\", \"No‚Ä¶\n$ dots_keyboard_response.rt                  <dbl> NA, 0.9339199, 0.8488816, 0‚Ä¶\n$ instruction_main_text.started              <dbl> NA, NA, NA, NA, NA, NA, 81.‚Ä¶\n$ instruction_main_text.stopped              <chr> NA, NA, NA, NA, NA, NA, \"No‚Ä¶\n$ instruction_main_keyboard_response.keys    <chr> NA, NA, NA, NA, NA, NA, \"sp‚Ä¶\n$ instruction_main_keyboard_response.rt      <dbl> NA, NA, NA, NA, NA, NA, 3.1‚Ä¶\n$ instruction_main_keyboard_response.started <dbl> NA, NA, NA, NA, NA, NA, 81.‚Ä¶\n$ instruction_main_keyboard_response.stopped <chr> NA, NA, NA, NA, NA, NA, \"No‚Ä¶\n$ Pseudonym                                  <chr> \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ‚Ä¶\n$ date                                       <chr> \"2022_Mar_07_1403\", \"2022_M‚Ä¶\n$ expName                                    <chr> \"rdk-discrimination\", \"rdk-‚Ä¶\n$ psychopyVersion                            <chr> \"03.02.21\", \"03.02.21\", \"03‚Ä¶\n$ frameRate                                  <dbl> 59.9, 59.9, 59.9, 59.9, 59.‚Ä¶"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#practice-trials-l√∂schen",
    "href": "pages/chapters/02_importing_data.html#practice-trials-l√∂schen",
    "title": "Daten importieren",
    "section": "Practice Trials l√∂schen",
    "text": "Practice Trials l√∂schen\n\nlibrary(kableExtra)\n\ntestdata |> \n  slice_head(n = 12) |> \n  kbl() |> \n  kable_paper(\"striped\", full_width = FALSE) |> \n  column_spec(2:7, bold = TRUE) |> \n  row_spec(1:6, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\n cue \n    direction \n    practice_block_loop.thisRepN \n    practice_block_loop.thisTrialN \n    practice_block_loop.thisN \n    practice_block_loop.thisIndex \n    main_blocks_loop.thisRepN \n    main_blocks_loop.thisTrialN \n    main_blocks_loop.thisN \n    main_blocks_loop.thisIndex \n    static_isi.started \n    static_isi.stopped \n    fixation_pre.started \n    fixation_pre.stopped \n    image.started \n    image.stopped \n    fixation_post.started \n    fixation_post.stopped \n    dots_background.started \n    dots_background.stopped \n    dots_stimulus.started \n    dots_stimulus.stopped \n    dots_keyboard_response.keys \n    dots_keyboard_response.started \n    dots_keyboard_response.stopped \n    feedback_text.started \n    feedback_text.stopped \n    dots_keyboard_response.rt \n    instruction_main_text.started \n    instruction_main_text.stopped \n    instruction_main_keyboard_response.keys \n    instruction_main_keyboard_response.rt \n    instruction_main_keyboard_response.started \n    instruction_main_keyboard_response.stopped \n    Pseudonym \n    date \n    expName \n    psychopyVersion \n    frameRate \n  \n\n\n none \n    right \n    0 \n    0 \n    0 \n    5 \n    NA \n    NA \n    NA \n    NA \n    0.0103343 \n    2.010334 \n    26.79425 \n    None \n    27.19849 \n    None \n    28.17814 \n    None \n    32.18642 \n    None \n    32.18642 \n    None \n    None \n    32.18642 \n    None \n    33.70200 \n    None \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n left \n    right \n    0 \n    1 \n    1 \n    2 \n    NA \n    NA \n    NA \n    NA \n    0.0320271 \n    2.032027 \n    36.16522 \n    None \n    36.28205 \n    None \n    37.28240 \n    None \n    41.30145 \n    None \n    41.30145 \n    None \n    f \n    41.30145 \n    None \n    42.28899 \n    None \n    0.9339199 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n right \n    right \n    0 \n    2 \n    2 \n    1 \n    NA \n    NA \n    NA \n    NA \n    0.0321732 \n    2.032173 \n    44.78521 \n    None \n    46.00329 \n    None \n    47.00374 \n    None \n    52.01072 \n    None \n    52.01072 \n    None \n    j \n    52.01072 \n    None \n    52.92295 \n    None \n    0.8488816 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n left \n    left \n    0 \n    3 \n    3 \n    0 \n    NA \n    NA \n    NA \n    NA \n    0.0321533 \n    2.032153 \n    55.39138 \n    None \n    56.19407 \n    None \n    57.22527 \n    None \n    61.23181 \n    None \n    61.23181 \n    None \n    f \n    61.23181 \n    None \n    62.21611 \n    None \n    0.9396018 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n none \n    left \n    0 \n    4 \n    4 \n    4 \n    NA \n    NA \n    NA \n    NA \n    0.0321391 \n    2.032139 \n    64.71204 \n    None \n    64.81315 \n    None \n    65.84603 \n    None \n    69.25240 \n    None \n    69.25240 \n    None \n    None \n    69.25240 \n    None \n    70.78541 \n    None \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n right \n    left \n    0 \n    5 \n    5 \n    3 \n    NA \n    NA \n    NA \n    NA \n    0.0323178 \n    2.032318 \n    73.24960 \n    None \n    74.45209 \n    None \n    75.48391 \n    None \n    79.99045 \n    None \n    79.99045 \n    None \n    f \n    79.99045 \n    None \n    80.80311 \n    None \n    0.7490084 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    81.30346 \n    None \n    space \n    3.187924 \n    81.30346 \n    None \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n right \n    right \n    NA \n    NA \n    NA \n    NA \n    0 \n    0 \n    0 \n    18 \n    0.0160001 \n    2.016000 \n    86.52245 \n    None \n    86.89231 \n    None \n    87.92302 \n    None \n    92.92987 \n    None \n    92.92987 \n    None \n    j \n    92.92987 \n    None \n    93.70924 \n    None \n    0.7136441 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n right \n    right \n    NA \n    NA \n    NA \n    NA \n    0 \n    1 \n    1 \n    31 \n    0.0318162 \n    2.031816 \n    96.17699 \n    None \n    96.54602 \n    None \n    97.57770 \n    None \n    101.58423 \n    None \n    101.58423 \n    None \n    j \n    101.58423 \n    None \n    102.26673 \n    None \n    0.6271285 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n none \n    right \n    NA \n    NA \n    NA \n    NA \n    0 \n    2 \n    2 \n    66 \n    0.0321148 \n    2.032115 \n    104.76463 \n    None \n    105.13302 \n    None \n    106.16508 \n    None \n    110.67183 \n    None \n    110.67183 \n    None \n    f \n    110.67183 \n    None \n    111.38828 \n    None \n    0.6703410 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n none \n    right \n    NA \n    NA \n    NA \n    NA \n    0 \n    3 \n    3 \n    75 \n    0.0321121 \n    2.032112 \n    113.88535 \n    None \n    115.08794 \n    None \n    116.11989 \n    None \n    119.52612 \n    None \n    119.52612 \n    None \n    j \n    119.52612 \n    None \n    120.15512 \n    None \n    0.5738488 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n left \n    left \n    NA \n    NA \n    NA \n    NA \n    0 \n    4 \n    4 \n    13 \n    0.0321118 \n    2.032112 \n    122.62295 \n    None \n    123.82583 \n    None \n    124.85742 \n    None \n    129.36397 \n    None \n    129.36397 \n    None \n    j \n    129.36397 \n    None \n    130.25975 \n    None \n    0.8405913 \n    NA \n    NA \n    NA \n    NA \n    NA \n    NA \n    ZZ \n    2022_Mar_07_1403 \n    rdk-discrimination \n    03.02.21 \n    59.9 \n  \n\n\n\n\n\ntestdata |> \n  slice_head(n = 12) |> \n  select(starts_with(\"main_block\")) |> \n  kbl() |> \n  kable_paper(\"striped\", full_width = FALSE) |> \n  row_spec(1:7, bold = TRUE, color = \"white\", background = \"#D7261E\")\n\n\n\n main_blocks_loop.thisRepN \n    main_blocks_loop.thisTrialN \n    main_blocks_loop.thisN \n    main_blocks_loop.thisIndex \n  \n\n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n NA \n    NA \n    NA \n    NA \n  \n\n 0 \n    0 \n    0 \n    18 \n  \n\n 0 \n    1 \n    1 \n    31 \n  \n\n 0 \n    2 \n    2 \n    66 \n  \n\n 0 \n    3 \n    3 \n    75 \n  \n\n 0 \n    4 \n    4 \n    13 \n  \n\n\n\n\nDie Variable main_blocks_loop.thisN ist die Trialnummer. Diese k√∂nnen wir verwenden, um die Zeilen auszuschliessen, die nicht zum Main Block geh√∂ren.\n\ntestdata |> \n    filter(!is.na(main_blocks_loop.thisN)) |>\n    select(-contains(\"practice_block_loop\"))\n\n# A tibble: 160 √ó 35\n   cue   direction main_blocks_loop.thisRepN main_blocks_loop.‚Ä¶ main_blocks_loo‚Ä¶\n   <chr> <chr>                         <dbl>              <dbl>            <dbl>\n 1 right right                             0                  0                0\n 2 right right                             0                  1                1\n 3 none  right                             0                  2                2\n 4 none  right                             0                  3                3\n 5 left  left                              0                  4                4\n 6 none  right                             0                  5                5\n 7 none  left                              0                  6                6\n 8 left  left                              0                  7                7\n 9 left  right                             0                  8                8\n10 none  right                             0                  9                9\n# ‚Ä¶ with 150 more rows, and 30 more variables:\n#   main_blocks_loop.thisIndex <dbl>, static_isi.started <dbl>,\n#   static_isi.stopped <dbl>, fixation_pre.started <dbl>,\n#   fixation_pre.stopped <chr>, image.started <dbl>, image.stopped <chr>,\n#   fixation_post.started <dbl>, fixation_post.stopped <chr>,\n#   dots_background.started <dbl>, dots_background.stopped <chr>,\n#   dots_stimulus.started <dbl>, dots_stimulus.stopped <chr>, ‚Ä¶"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#variablen-ausw√§hlen",
    "href": "pages/chapters/02_importing_data.html#variablen-ausw√§hlen",
    "title": "Daten importieren",
    "section": "Variablen ausw√§hlen",
    "text": "Variablen ausw√§hlen\n\ntestdata |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n# A tibble: 167 √ó 23\n   cue   direction practice_block_loop.thisRe‚Ä¶ practice_block_‚Ä¶ practice_block_‚Ä¶\n   <chr> <chr>                           <dbl>            <dbl>            <dbl>\n 1 none  right                               0                0                0\n 2 left  right                               0                1                1\n 3 right right                               0                2                2\n 4 left  left                                0                3                3\n 5 none  left                                0                4                4\n 6 right left                                0                5                5\n 7 <NA>  <NA>                               NA               NA               NA\n 8 right right                              NA               NA               NA\n 9 right right                              NA               NA               NA\n10 none  right                              NA               NA               NA\n# ‚Ä¶ with 157 more rows, and 18 more variables:\n#   practice_block_loop.thisIndex <dbl>, main_blocks_loop.thisRepN <dbl>,\n#   main_blocks_loop.thisTrialN <dbl>, main_blocks_loop.thisN <dbl>,\n#   main_blocks_loop.thisIndex <dbl>, dots_background.started <dbl>,\n#   dots_background.stopped <chr>, dots_stimulus.started <dbl>,\n#   dots_stimulus.stopped <chr>, dots_keyboard_response.keys <chr>,\n#   dots_keyboard_response.started <dbl>, ‚Ä¶\n\n\n\ntestdata <- testdata |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\ntestdata\n\n# A tibble: 167 √ó 23\n   cue   direction practice_block_loop.thisRe‚Ä¶ practice_block_‚Ä¶ practice_block_‚Ä¶\n   <chr> <chr>                           <dbl>            <dbl>            <dbl>\n 1 none  right                               0                0                0\n 2 left  right                               0                1                1\n 3 right right                               0                2                2\n 4 left  left                                0                3                3\n 5 none  left                                0                4                4\n 6 right left                                0                5                5\n 7 <NA>  <NA>                               NA               NA               NA\n 8 right right                              NA               NA               NA\n 9 right right                              NA               NA               NA\n10 none  right                              NA               NA               NA\n# ‚Ä¶ with 157 more rows, and 18 more variables:\n#   practice_block_loop.thisIndex <dbl>, main_blocks_loop.thisRepN <dbl>,\n#   main_blocks_loop.thisTrialN <dbl>, main_blocks_loop.thisN <dbl>,\n#   main_blocks_loop.thisIndex <dbl>, dots_background.started <dbl>,\n#   dots_background.stopped <chr>, dots_stimulus.started <dbl>,\n#   dots_stimulus.stopped <chr>, dots_keyboard_response.keys <chr>,\n#   dots_keyboard_response.started <dbl>, ‚Ä¶"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#variablen-umbennen",
    "href": "pages/chapters/02_importing_data.html#variablen-umbennen",
    "title": "Daten importieren",
    "section": "Variablen umbennen",
    "text": "Variablen umbennen\n\ntestdata <- testdata |>\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)\n\n\ntestdata\n\n# A tibble: 167 √ó 6\n   trial ID    cue   direction response     rt\n   <dbl> <chr> <chr> <chr>     <chr>     <dbl>\n 1    NA ZZ    none  right     None     NA    \n 2    NA ZZ    left  right     f         0.934\n 3    NA ZZ    right right     j         0.849\n 4    NA ZZ    left  left      f         0.940\n 5    NA ZZ    none  left      None     NA    \n 6    NA ZZ    right left      f         0.749\n 7    NA ZZ    <NA>  <NA>      <NA>     NA    \n 8     0 ZZ    right right     j         0.714\n 9     1 ZZ    right right     j         0.627\n10     2 ZZ    none  right     f         0.670\n# ‚Ä¶ with 157 more rows"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#neue-variablen-definieren",
    "href": "pages/chapters/02_importing_data.html#neue-variablen-definieren",
    "title": "Daten importieren",
    "section": "Neue Variablen definieren",
    "text": "Neue Variablen definieren\n\ntestdata <- testdata |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\nAlternative:\n\ntestdata <- testdata |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = as.numeric(choice == \"right\"))\n\nWir erstellen ausserdem hier eine Variable, welche angibt, ob der Cue valid, invalid oder neutral war. Ein Cue ist genau dann valide, wenn er dieselbe Richtung hat wie der RDK Stimulus, d.h. cue == direction.\n\ntestdata <- testdata |>\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\n\ntestdata <- testdata |>\n    mutate(correct = as.numeric(choice == direction))"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#gruppierungsvariablen",
    "href": "pages/chapters/02_importing_data.html#gruppierungsvariablen",
    "title": "Daten importieren",
    "section": "Gruppierungsvariablen",
    "text": "Gruppierungsvariablen\n\nglimpse(testdata)\n\nRows: 167\nColumns: 9\n$ trial     <dbl> NA, NA, NA, NA, NA, NA, NA, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10‚Ä¶\n$ ID        <chr> \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", \"ZZ\", ‚Ä¶\n$ cue       <chr> \"none\", \"left\", \"right\", \"left\", \"none\", \"right\", NA, \"right‚Ä¶\n$ direction <chr> \"right\", \"right\", \"right\", \"left\", \"left\", \"left\", NA, \"righ‚Ä¶\n$ response  <dbl> 0, 0, 1, 0, 0, 0, NA, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,‚Ä¶\n$ rt        <dbl> NA, 0.9339199, 0.8488816, 0.9396018, NA, 0.7490084, NA, 0.71‚Ä¶\n$ choice    <chr> \"left\", \"left\", \"right\", \"left\", \"left\", \"left\", NA, \"right\"‚Ä¶\n$ condition <chr> \"neutral\", \"invalid\", \"valid\", \"valid\", \"neutral\", \"invalid\"‚Ä¶\n$ correct   <dbl> 0, 0, 1, 1, 1, 1, NA, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,‚Ä¶\n\n\n\ntestdata <- testdata |>\n    mutate_if(is.character, as.factor)\n\n\nglimpse(testdata)\n\nRows: 167\nColumns: 9\n$ trial     <dbl> NA, NA, NA, NA, NA, NA, NA, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10‚Ä¶\n$ ID        <fct> ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ZZ, ‚Ä¶\n$ cue       <fct> none, left, right, left, none, right, NA, right, right, none‚Ä¶\n$ direction <fct> right, right, right, left, left, left, NA, right, right, rig‚Ä¶\n$ response  <dbl> 0, 0, 1, 0, 0, 0, NA, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0,‚Ä¶\n$ rt        <dbl> NA, 0.9339199, 0.8488816, 0.9396018, NA, 0.7490084, NA, 0.71‚Ä¶\n$ choice    <fct> left, left, right, left, left, left, NA, right, right, left,‚Ä¶\n$ condition <fct> neutral, invalid, valid, valid, neutral, invalid, NA, valid,‚Ä¶\n$ correct   <dbl> 0, 0, 1, 1, 1, 1, NA, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,‚Ä¶"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#accuracy-pro-bedingung",
    "href": "pages/chapters/02_importing_data.html#accuracy-pro-bedingung",
    "title": "Daten importieren",
    "section": "Accuracy pro Bedingung",
    "text": "Accuracy pro Bedingung\nWir k√∂nnen nun die accuracy in jeder Cue-Bedingung berechnen. Es gibt hier zwei M√∂glichkeiten: wir berechen die Anzahl Trials (N), und die Anzahl korrekter Antworten (ncorrect) separat. Der Anteil korrekter Antworten ist dann einfach ncorrect/N. Dasselbe Ergebnis erhalten wir, wenn wir einfach den Mittelwert der korrekten Antworten nehmen.\n\ntestaccuracy <- testdata |>\n    group_by(condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = ncorrect/N,\n              accuracy2 = mean(correct))\n\ntestaccuracy\n\n# A tibble: 4 √ó 5\n  condition     N ncorrect accuracy accuracy2\n  <fct>     <int>    <dbl>    <dbl>     <dbl>\n1 invalid      18       14    0.778     0.778\n2 neutral      82       67    0.817     0.817\n3 valid        66       62    0.939     0.939\n4 <NA>          1       NA   NA        NA"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#funktion-definieren",
    "href": "pages/chapters/02_importing_data.html#funktion-definieren",
    "title": "Daten importieren",
    "section": "Funktion definieren",
    "text": "Funktion definieren\nNun wollen wir die ersten paar Schritte gleichzeitig auf mehrere Files anwenden:\n\n\nCSV File einlesen\nFilename hinzuf√ºgen\nPractice Trials l√∂schen\nPractice Variablen l√∂schen\n\nDieser Vorgang ist in R ziemlich elegant. Anstatt dass wir manuell √ºber alle Files iterieren m√ºssen, k√∂nnen wir eine Funktion definieren, die wir auf ein File anwenden k√∂nnen, und dann wenden wir diese Funktion auf alle Files an.\n\nMit map_* Funktionen k√∂nnen wir eine Funktion auf alle Elemente einer Liste anwenden. map_dfr macht genau das, und gibt einen Dataframe als Output, in welchem die einzelnen Elemente row-wise zusamengesetzt werden.\nDie Funktion, welche wir auf ein einzelnes .csv File anweden m√∂chten, ist diese:\n\nimport_function <- function(filename) {\n    read_csv(filename) |>\n        mutate(filename = basename(filename)) |>\n        filter(!is.na(main_blocks_loop.thisN)) |>\n        select(-contains(\"practice_block_loop\"))\n}\n\n\nProbieren Sie die Funktion mit dem einzelnen .csv File von oben."
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#alle-files-in-einem-ordner-auflisten",
    "href": "pages/chapters/02_importing_data.html#alle-files-in-einem-ordner-auflisten",
    "title": "Daten importieren",
    "section": "Alle Files in einem Ordner auflisten",
    "text": "Alle Files in einem Ordner auflisten\n\ndatadir <- \"data/\"\nlist_of_files <- datadir |>\n    list.files(pattern = \"csv\", recursive = TRUE, full.names = TRUE)\n\n\nlist_of_files\n\n[1] \"data//JH_rdk-discrimination_2022_Mar_07_1403.csv\"   \n[2] \"data//NS_rdk-discrimination_2022_Mar_07_1331.csv\"   \n[3] \"data//rh_rdk-discrimination_2022_Mar_02_1105.csv\"   \n[4] \"data//sb_rdk-discrimination_2022_Mar_06_0746.csv\"   \n[5] \"data//SS91_rdk-discrimination_2022_Mar_06_0953.csv\" \n[6] \"data//VP1_rdk-discrimination_2022_Mar_07_1237.csv\"  \n[7] \"data//VP2_rdk-discrimination_2022_Mar_07_1302.csv\"  \n[8] \"data//VPN01_rdk-discrimination_2022_Mar_01_2142.csv\"\n[9] \"data//VPN02_rdk-discrimination_2022_Mar_01_2208.csv\""
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#funktion-auf-liste-anwenden",
    "href": "pages/chapters/02_importing_data.html#funktion-auf-liste-anwenden",
    "title": "Daten importieren",
    "section": "Funktion auf Liste anwenden",
    "text": "Funktion auf Liste anwenden\n\ndata <- list_of_files |> \n    map_dfr(~ import_function(.x))"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#variablen-ausw√§hlen-und-umbennen",
    "href": "pages/chapters/02_importing_data.html#variablen-ausw√§hlen-und-umbennen",
    "title": "Daten importieren",
    "section": "Variablen ausw√§hlen und umbennen",
    "text": "Variablen ausw√§hlen und umbennen\n\ndata <- data |>\n    select(-contains(\"static\"),\n           -contains(\"fixation\"),\n           -contains(\"image\"),\n           -contains(\"instruction\"),\n           -contains(\"feedback\"))\n\n\ndata <- data |>\n    select(trial = main_blocks_loop.thisN,\n           ID = Pseudonym,\n           cue,\n           direction,\n           response = dots_keyboard_response.keys,\n           rt = dots_keyboard_response.rt)"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#neue-variablen-definieren-1",
    "href": "pages/chapters/02_importing_data.html#neue-variablen-definieren-1",
    "title": "Daten importieren",
    "section": "Neue Variablen definieren",
    "text": "Neue Variablen definieren\nKorrekte Antworten\n\ndata <- data |>\n    mutate(choice = if_else(response == \"j\", \"right\", \"left\"),\n           response = if_else(choice == \"right\", 1, 0))\n\n\ndata <- data |>\n    mutate(correct = as.numeric(choice == direction))\n\n\nglimpse(data)\n\nRows: 1,440\nColumns: 8\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ ID        <chr> \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", \"JH\", ‚Ä¶\n$ cue       <chr> \"right\", \"right\", \"none\", \"none\", \"left\", \"none\", \"none\", \"l‚Ä¶\n$ direction <chr> \"right\", \"right\", \"right\", \"right\", \"left\", \"right\", \"left\",‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667‚Ä¶\n$ choice    <chr> \"right\", \"right\", \"left\", \"right\", \"right\", \"right\", \"right\"‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n\n\n\ndata |> \n  slice_head(n = 20)\n\n# A tibble: 20 √ó 8\n   trial ID    cue   direction response    rt choice correct\n   <dbl> <chr> <chr> <chr>        <dbl> <dbl> <chr>    <dbl>\n 1     0 JH    right right            1 0.714 right        1\n 2     1 JH    right right            1 0.627 right        1\n 3     2 JH    none  right            0 0.670 left         0\n 4     3 JH    none  right            1 0.574 right        1\n 5     4 JH    left  left             1 0.841 right        0\n 6     5 JH    none  right            1 0.668 right        1\n 7     6 JH    none  left             1 1.12  right        0\n 8     7 JH    left  left             0 0.640 left         1\n 9     8 JH    left  right            0 1.13  left         0\n10     9 JH    none  right            1 1.03  right        1\n11    10 JH    none  left             0 1.35  left         1\n12    11 JH    left  left             0 0.688 left         1\n13    12 JH    left  left             0 0.721 left         1\n14    13 JH    none  left             0 0.655 left         1\n15    14 JH    right right            1 1.02  right        1\n16    15 JH    none  right            1 1.12  right        1\n17    16 JH    left  left             0 1.08  left         1\n18    17 JH    right left             0 0.643 left         1\n19    18 JH    right right            1 0.716 right        1\n20    19 JH    left  left             0 0.578 left         1\n\n\nCue-Bedingungsvariable\n\ndata <- data |>\n    mutate(condition = case_when(cue == \"none\" ~ \"neutral\",\n                                 cue == direction ~ \"valid\",\n                                 cue != direction ~ \"invalid\"))\n\nDaten als CSV speichern\nAn dieser Stelle speichern wir den neu kreierten Datensatz als .csv File. Somit k√∂nnen wir die Daten einfach importieren, ohne die ganzen Schritte wiederholen zu m√ºssen.\n\ndata |> write_csv(file = \"data_clean/rdkdata.csv\")\n\n\ndata |> \n  slice_head(n = 20)\n\n# A tibble: 20 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <chr> <chr> <chr>        <dbl> <dbl> <chr>    <dbl> <chr>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n11    10 JH    none  left             0 1.35  left         1 neutral  \n12    11 JH    left  left             0 0.688 left         1 valid    \n13    12 JH    left  left             0 0.721 left         1 valid    \n14    13 JH    none  left             0 0.655 left         1 neutral  \n15    14 JH    right right            1 1.02  right        1 valid    \n16    15 JH    none  right            1 1.12  right        1 neutral  \n17    16 JH    left  left             0 1.08  left         1 valid    \n18    17 JH    right left             0 0.643 left         1 invalid  \n19    18 JH    right right            1 0.716 right        1 valid    \n20    19 JH    left  left             0 0.578 left         1 valid"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#gruppierungsvariablen-1",
    "href": "pages/chapters/02_importing_data.html#gruppierungsvariablen-1",
    "title": "Daten importieren",
    "section": "Gruppierungsvariablen",
    "text": "Gruppierungsvariablen\n\ndata <- data |>\n    mutate_if(is.character, as.factor)\n\n\nglimpse(data)\n\nRows: 1,440\nColumns: 9\n$ trial     <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ ID        <fct> JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, JH, ‚Ä¶\n$ cue       <fct> right, right, none, none, left, none, none, left, left, none‚Ä¶\n$ direction <fct> right, right, right, right, left, right, left, left, right, ‚Ä¶\n$ response  <dbl> 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ‚Ä¶\n$ rt        <dbl> 0.7136441, 0.6271285, 0.6703410, 0.5738488, 0.8405913, 0.667‚Ä¶\n$ choice    <fct> right, right, left, right, right, right, right, left, left, ‚Ä¶\n$ correct   <dbl> 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ‚Ä¶\n$ condition <fct> valid, valid, neutral, neutral, valid, neutral, neutral, val‚Ä¶"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#accuracy-pro-personbedingung",
    "href": "pages/chapters/02_importing_data.html#accuracy-pro-personbedingung",
    "title": "Daten importieren",
    "section": "Accuracy pro Person/Bedingung",
    "text": "Accuracy pro Person/Bedingung\nAccuracy pro Person und pro Bedingung berechnen.\n\naccuracy <- data |>\n    group_by(ID, condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n\n\n\naccuracy\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    invalid      16       13   0.812 \n 2 JH    neutral      80       66   0.825 \n 3 JH    valid        64       60   0.938 \n 4 NS    invalid      16       11   0.688 \n 5 NS    neutral      80       56   0.7   \n 6 NS    valid        64       58   0.906 \n 7 rh    invalid      16        2   0.125 \n 8 rh    neutral      80       64   0.8   \n 9 rh    valid        64       61   0.953 \n10 sb    invalid      16        1   0.0625\n# ‚Ä¶ with 17 more rows"
  },
  {
    "objectID": "pages/chapters/02_importing_data.html#visualisieren",
    "href": "pages/chapters/02_importing_data.html#visualisieren",
    "title": "Daten importieren",
    "section": "Visualisieren",
    "text": "Visualisieren\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Proportion correct\",\n    title = \"Accuracy per person/condition\"\n  ) +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html",
    "href": "pages/chapters/06_signal_detection_ii.html",
    "title": "Signal Detection Theory: II",
    "section": "",
    "text": "Note\n\n\n\nüëâ R Code f√ºr dieses Kapitel downloaden\nüëâ Daten downloaden"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#daten-importieren",
    "href": "pages/chapters/06_signal_detection_ii.html#daten-importieren",
    "title": "Signal Detection Theory: II",
    "section": "Daten importieren",
    "text": "Daten importieren\nZuerst die Daten downloaden, und speichern.\n\nlibrary(tidyverse)\nd <- read_csv(\"data/session-6.csv\")"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#variablen-bearbeiten",
    "href": "pages/chapters/06_signal_detection_ii.html#variablen-bearbeiten",
    "title": "Signal Detection Theory: II",
    "section": "Variablen bearbeiten",
    "text": "Variablen bearbeiten\nZu factor konvertieren, etc.\n\nd <- d |>\n    select(ID, condition, cue, direction, choice) |>\n    mutate(across(where(is.character), ~as_factor(.)),\n           cue = fct_relevel(cue, \"left\", \"none\", \"right\")) |>\n    drop_na()"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#trials-klassifizieren",
    "href": "pages/chapters/06_signal_detection_ii.html#trials-klassifizieren",
    "title": "Signal Detection Theory: II",
    "section": "Trials klassifizieren",
    "text": "Trials klassifizieren\nAls Hit, Miss, CR und FA.\n\nsdt <- d |>\n    mutate(type = case_when(\n        direction == \"___\" & choice == \"___\" ~ \"___\"),\n        ___,\n        ___,\n        ___)\n\n\nsdt\n\n# A tibble: 2,362 √ó 6\n   ID     condition cue   direction choice type \n   <fct>  <fct>     <fct> <fct>     <fct>  <chr>\n 1 chch04 valid     left  left      left   CR   \n 2 chch04 valid     left  left      left   CR   \n 3 chch04 valid     left  left      right  FA   \n 4 chch04 invalid   right left      left   CR   \n 5 chch04 neutral   none  left      left   CR   \n 6 chch04 valid     left  left      left   CR   \n 7 chch04 invalid   right left      left   CR   \n 8 chch04 valid     left  left      left   CR   \n 9 chch04 neutral   none  left      left   CR   \n10 chch04 neutral   none  right     left   Miss \n# ‚Ä¶ with 2,352 more rows"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#sdt-kennzahlen-zusammenz√§hlen",
    "href": "pages/chapters/06_signal_detection_ii.html#sdt-kennzahlen-zusammenz√§hlen",
    "title": "Signal Detection Theory: II",
    "section": "SDT Kennzahlen zusammenz√§hlen",
    "text": "SDT Kennzahlen zusammenz√§hlen\n\nsdt_summary <- sdt |>\n    group_by(ID, cue) |>\n    count(type)\n\n\nsdt_summary\n\n# A tibble: 170 √ó 4\n# Groups:   ID, cue [45]\n   ID     cue   type      n\n   <fct>  <fct> <chr> <int>\n 1 chch04 left  CR       29\n 2 chch04 left  FA        3\n 3 chch04 left  Hit       7\n 4 chch04 left  Miss      1\n 5 chch04 none  CR       38\n 6 chch04 none  FA        2\n 7 chch04 none  Hit      34\n 8 chch04 none  Miss      6\n 9 chch04 right CR        5\n10 chch04 right FA        3\n# ‚Ä¶ with 160 more rows"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#von-wide-zu-long-konvertieren",
    "href": "pages/chapters/06_signal_detection_ii.html#von-wide-zu-long-konvertieren",
    "title": "Signal Detection Theory: II",
    "section": "Von wide zu long konvertieren",
    "text": "Von wide zu long konvertieren\n\nsdt_summary <- sdt_summary |>\n    pivot_wider(names_from = type, values_from = n)\n\n\nsdt_summary\n\n# A tibble: 45 √ó 6\n# Groups:   ID, cue [45]\n   ID     cue      CR    FA   Hit  Miss\n   <fct>  <fct> <int> <int> <int> <int>\n 1 chch04 left     29     3     7     1\n 2 chch04 none     38     2    34     6\n 3 chch04 right     5     3    25     7\n 4 chmi14 left     21    10     5     3\n 5 chmi14 none     18    19    29     7\n 6 chmi14 right     3     4    26     4\n 7 J      left     19    12     5     3\n 8 J      none     23    16    33     6\n 9 J      right     6     2    20    12\n10 jh     left     32    NA     5     3\n# ‚Ä¶ with 35 more rows"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#funktionen-definieren",
    "href": "pages/chapters/06_signal_detection_ii.html#funktionen-definieren",
    "title": "Signal Detection Theory: II",
    "section": "Funktionen definieren",
    "text": "Funktionen definieren\n\nreplace_NA <- function(x) {\n    x = ifelse(is.na(x), 0, x)\n    x\n}\n\ncorrect_zero_one <- function(x) {\n    if (identical(x, 0)) {\n        x = x + 0.001\n    } else if (identical(x, 1)) {\n        x = x - 0.001\n    }\n    x\n}"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#nas-ersetzen",
    "href": "pages/chapters/06_signal_detection_ii.html#nas-ersetzen",
    "title": "Signal Detection Theory: II",
    "section": "NAs ersetzen",
    "text": "NAs ersetzen\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(Hit, Miss, FA, CR), replace_NA))"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#hit-rate-und-false-alarm-rate-berechnen",
    "href": "pages/chapters/06_signal_detection_ii.html#hit-rate-und-false-alarm-rate-berechnen",
    "title": "Signal Detection Theory: II",
    "section": "Hit Rate und False Alarm Rate berechnen",
    "text": "Hit Rate und False Alarm Rate berechnen\n\nsdt_summary <- sdt_summary |>\n    mutate(hit_rate = ___,\n           fa_rate = ___)"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#werte-0-und-1-korrigieren",
    "href": "pages/chapters/06_signal_detection_ii.html#werte-0-und-1-korrigieren",
    "title": "Signal Detection Theory: II",
    "section": "Werte 0 und 1 korrigieren",
    "text": "Werte 0 und 1 korrigieren\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(hit_rate, fa_rate), correct_zero_one))"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#z-transformation",
    "href": "pages/chapters/06_signal_detection_ii.html#z-transformation",
    "title": "Signal Detection Theory: II",
    "section": "Z-Transformation",
    "text": "Z-Transformation\n\nsdt_summary <- sdt_summary |>\n    mutate(zhr = ___,\n           zfa = ___)"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#sdt-kennzahlen-berechnen",
    "href": "pages/chapters/06_signal_detection_ii.html#sdt-kennzahlen-berechnen",
    "title": "Signal Detection Theory: II",
    "section": "SDT Kennzahlen berechnen",
    "text": "SDT Kennzahlen berechnen\n\nsdt_summary <- sdt_summary |>\n    mutate(dprime = ___,\n           k = ___,\n           c = ___) |>\n    mutate(across(c(dprime, k, c), round, 2))"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#variablen-ausw√§hlen",
    "href": "pages/chapters/06_signal_detection_ii.html#variablen-ausw√§hlen",
    "title": "Signal Detection Theory: II",
    "section": "Variablen ausw√§hlen",
    "text": "Variablen ausw√§hlen\n\nsdt_final <- sdt_summary |>\n    select(ID, cue, dprime, k, c)"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#eine-person-ausw√§hlen.",
    "href": "pages/chapters/06_signal_detection_ii.html#eine-person-ausw√§hlen.",
    "title": "Signal Detection Theory: II",
    "section": "Eine Person ausw√§hlen.",
    "text": "Eine Person ausw√§hlen.\n\nSU6460 <- d |>\n    filter(ID %in% \"SU6460\")\n\nSU6460_sdt <- sdt_final |>\n    filter(ID %in% \"SU6460\")"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#visualisieren",
    "href": "pages/chapters/06_signal_detection_ii.html#visualisieren",
    "title": "Signal Detection Theory: II",
    "section": "Visualisieren",
    "text": "Visualisieren\n\nSU6460_sdt\n\n# A tibble: 3 √ó 5\n# Groups:   ID, cue [3]\n  ID     cue   dprime     k     c\n  <fct>  <fct>  <dbl> <dbl> <dbl>\n1 SU6460 left    0.32  0    -0.16\n2 SU6460 none    0.3  -0.23 -0.38\n3 SU6460 right  -0.27 -0.67 -0.54\n\n\n\nSU6460_sdt |>\n    ggplot(aes(x = cue, y = dprime, group = 1)) +\n    geom_line() +\n    geom_point(shape = 21, size = 3, fill = \"white\")\n\n\n\n\n\nSU6460_sdt |>\n    ggplot(aes(x = cue, y = c, group = 1)) +\n    geom_line() +\n    geom_point(shape = 21, size = 3, fill = \"white\")"
  },
  {
    "objectID": "pages/chapters/06_signal_detection_ii.html#generalized-linear-model",
    "href": "pages/chapters/06_signal_detection_ii.html#generalized-linear-model",
    "title": "Signal Detection Theory: II",
    "section": "Generalized Linear Model",
    "text": "Generalized Linear Model\nCheck levels: right muss die zweite Faktorstufe sein!\n\nlevels(SU6460$choice)\n\n[1] \"left\"  \"right\"\n\n\n\nSU6460_glm_k_left <- glm(choice ~ direction,\n                      family = binomial(link = \"probit\"),\n                      data = SU6460 |> filter(cue == \"left\"))\n\nsummary(SU6460_glm_k_left)\n\n\nCall:\nglm(formula = choice ~ direction, family = binomial(link = \"probit\"), \n    data = filter(SU6460, cue == \"left\"))\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4006  -1.1774   0.9695   1.1774   1.1774  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)\n(Intercept)    2.208e-17  2.216e-01   0.000    1.000\ndirectionright 3.186e-01  5.028e-01   0.634    0.526\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 55.352  on 39  degrees of freedom\nResidual deviance: 54.946  on 38  degrees of freedom\nAIC: 58.946\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nSU6460_glm_k_right <- glm(choice ~ direction,\n                       family = binomial(link = \"probit\"),\n                       data = SU6460 |> filter(cue == \"right\"))\n\nsummary(SU6460_glm_k_right)\n\n\nCall:\nglm(formula = choice ~ direction, family = binomial(link = \"probit\"), \n    data = filter(SU6460, cue == \"right\"))\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6651  -1.4614   0.9178   0.9178   0.9178  \n\nCoefficients:\n               Estimate Std. Error z value Pr(>|z|)\n(Intercept)      0.6745     0.4818   1.400    0.162\ndirectionright  -0.2722     0.5331  -0.511    0.610\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 50.446  on 39  degrees of freedom\nResidual deviance: 50.181  on 38  degrees of freedom\nAIC: 54.181\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nSU6460 <- SU6460 |>\n    mutate(dir = if_else(direction == \"left\", -1/2, 1/2))\n\n\nSU6460_glm_c_left <- glm(choice ~ dir,\n                       family = binomial(link = \"probit\"),\n                       data = SU6460 |> filter(cue == \"left\"))\nsummary(SU6460_glm_c_left)\n\n\nCall:\nglm(formula = choice ~ dir, family = binomial(link = \"probit\"), \n    data = filter(SU6460, cue == \"left\"))\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.4006  -1.1774   0.9695   1.1774   1.1774  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)   0.1593     0.2514   0.634    0.526\ndir           0.3186     0.5028   0.634    0.526\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 55.352  on 39  degrees of freedom\nResidual deviance: 54.946  on 38  degrees of freedom\nAIC: 58.946\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nSU6460_glm_c_right <- glm(choice ~ dir,\n                        family = binomial(link = \"probit\"),\n                        data = SU6460 |> filter(cue == \"right\"))\n\nsummary(SU6460_glm_c_right)\n\n\nCall:\nglm(formula = choice ~ dir, family = binomial(link = \"probit\"), \n    data = filter(SU6460, cue == \"right\"))\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6651  -1.4614   0.9178   0.9178   0.9178  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept)   0.5384     0.2665   2.020   0.0434 *\ndir          -0.2722     0.5331  -0.511   0.6096  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 50.446  on 39  degrees of freedom\nResidual deviance: 50.181  on 38  degrees of freedom\nAIC: 54.181\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "pages/chapters/07_response_times_i.html",
    "href": "pages/chapters/07_response_times_i.html",
    "title": "Reaktionszeiten: I",
    "section": "",
    "text": "Note\n\n\n\nüëâ R Code f√ºr dieses Kapitel downloaden\nüëâ Daten downloaden"
  },
  {
    "objectID": "pages/chapters/07_response_times_i.html#zusammenfassen-zentrale-tendenz-und-dispersion",
    "href": "pages/chapters/07_response_times_i.html#zusammenfassen-zentrale-tendenz-und-dispersion",
    "title": "Reaktionszeiten: I",
    "section": "Zusammenfassen: zentrale Tendenz und Dispersion",
    "text": "Zusammenfassen: zentrale Tendenz und Dispersion\nMittelwert und Standardabweichung\n\nd %>% \n  group_by(group) %>% \n  summarise(mean = mean(rt),\n            sd = sd(rt))\n\n# A tibble: 2 √ó 3\n  group    mean    sd\n  <fct>   <dbl> <dbl>\n1 control  822.  171.\n2 adhd     839.  214.\n\n\nMedian und Interquartilsbereich\nDer Interquartilsbereich repr√§ntiert den Unterschied zwischen dem ersten (25. Perzentil) und dritten (75. Perzentil) Quartil. In diesem Bereich befinden sich 50% der Datenpunkte.\n\nd %>% \n  group_by(group) %>% \n  summarise(mean = median(rt),\n            q25 = quantile(rt, probs = 0.25),\n            q75 = quantile(rt, probs = 0.75)) |> \n  mutate(IQR = q75 - q25)\n\n# A tibble: 2 √ó 5\n  group    mean   q25   q75   IQR\n  <fct>   <dbl> <dbl> <dbl> <dbl>\n1 control  782.  694.  898.  205.\n2 adhd     784.  694.  923.  228.\n\n\n\nd %>% \n  group_by(group) %>% \n  summarise(mean = median(rt),\n            IQR = IQR(rt))\n\n# A tibble: 2 √ó 3\n  group    mean   IQR\n  <fct>   <dbl> <dbl>\n1 control  782.  205.\n2 adhd     784.  228.\n\n\n\nfuns <- list(mean = mean, median = median, \n             sd = sd, IQR = IQR)\n\nby_group <- d |>\n  group_by(group) |>\n  summarise(across(rt, funs, .names = \"{.fn}\")) |>\n  mutate(across(where(is.numeric), ~round(., 2)))\n\n\nby_group\n\n# A tibble: 2 √ó 5\n  group    mean median    sd   IQR\n  <fct>   <dbl>  <dbl> <dbl> <dbl>\n1 control  822.   782.  171.  205.\n2 adhd     839.   784.  214.  228.\n\n\n\np1 +\n  geom_vline(aes(xintercept = mean), \n             data = by_group,\n             color = \"steelblue\",\n             lwd = 1.5) +\n  geom_vline(aes(xintercept = median), \n             data = by_group, \n             color = \"red\",\n             lwd = 1.5)\n\n\n\n\nZentrale Tendenz bei schiefen Verteilungen\nSowohl Mittelwert als auch Median sind jedoch problematisch als Masse der zentralen Tendenz f√ºr asymmetrische Verteilungen. Der Mittelwert kann durch eine hohe Schiefe und Ausreissern verschoben werden, und repr√§sentiert die zentrale Tendenz der Verteilung nicht besonders gut.\nDer Median ist ein besseres Mass f√ºr eine typische Beobachtung aus dieser Verteilung, ist jedoch nicht erwartungstreu, das heisst der Median √ºbersch√§tzt den Populationsmedian. Der Grad der √úbersch√§tzung steigt mit sinkender Anzahl Beobachtungen (d.h. vor allem bei kleinen Stichproben).\nQuantile\n\ndeciles <- seq(0.1, 0.9, length.out = 9)\n\n\nquantile_fun <- function(x, probs = c(0.25, 0.5, 0.75)) {\n  tibble(rt = quantile(x, probs, type = 8), quantile = probs)\n}\n\n\nd_quantiles <- d %>% \n  group_by(group) %>% \n  summarise(quantile_fun(rt, probs = deciles))\n\n\nd_quantiles\n\n# A tibble: 18 √ó 3\n# Groups:   group [2]\n   group      rt quantile\n   <fct>   <dbl>    <dbl>\n 1 control  649.      0.1\n 2 control  684.      0.2\n 3 control  711.      0.3\n 4 control  740.      0.4\n 5 control  782.      0.5\n 6 control  826.      0.6\n 7 control  875.      0.7\n 8 control  949.      0.8\n 9 control 1045.      0.9\n10 adhd     631.      0.1\n11 adhd     674.      0.2\n12 adhd     712.      0.3\n13 adhd     745.      0.4\n14 adhd     784.      0.5\n15 adhd     828.      0.6\n16 adhd     874.      0.7\n17 adhd     980.      0.8\n18 adhd    1108.      0.9\n\n\nShift function\nWir m√ºssen nun den Dataframe mit den Quantilen ins ‚Äúwide‚Äù Format konvertieren, um zwei Spalten f√ºr die control und adhd Gruppen zu erhalten. Danach k√∂nnen wir die Differenzen zwischen den Gruppen f√ºr jedes Quantil berechnen.\n\nd_quantile_differences <- d_quantiles |> \n  pivot_wider(names_from = \"group\", values_from = \"rt\") \n\n\nd_quantile_differences\n\n# A tibble: 9 √ó 3\n  quantile control  adhd\n     <dbl>   <dbl> <dbl>\n1      0.1    649.  631.\n2      0.2    684.  674.\n3      0.3    711.  712.\n4      0.4    740.  745.\n5      0.5    782.  784.\n6      0.6    826.  828.\n7      0.7    875.  874.\n8      0.8    949.  980.\n9      0.9   1045. 1108.\n\n\n\nd_quantile_differences <- d_quantile_differences |> \n    mutate(`control - adhd` = control - adhd)\n\n\nd_quantile_differences\n\n# A tibble: 9 √ó 4\n  quantile control  adhd `control - adhd`\n     <dbl>   <dbl> <dbl>            <dbl>\n1      0.1    649.  631.            18.2 \n2      0.2    684.  674.            10.6 \n3      0.3    711.  712.            -1.45\n4      0.4    740.  745.            -4.99\n5      0.5    782.  784.            -2.16\n6      0.6    826.  828.            -1.57\n7      0.7    875.  874.             1.42\n8      0.8    949.  980.           -30.4 \n9      0.9   1045. 1108.           -62.8 \n\n\nShift function grafisch darstellen\n\nd_quantile_differences %>% \n  ggplot(aes(x = control, y = `control - adhd`)) +\n  geom_hline(yintercept = 0, linetype = 3) +\n  geom_vline(xintercept = d_quantile_differences %>% \n               filter(quantile == \"50%\") %>% \n               select(adhd) %>% \n               pull(), linetype = 3) +\n  geom_line(aes(group = 1), color = \"steelblue\", size = 2) +\n  geom_point(shape = 21, color = \"steelblue\", fill = \"white\", size = 5, stroke = 1) +\n  coord_cartesian(ylim = c(-300, 300))\n\n\n\n\n\ninstall.packages(\"remotes\")\nremotes::install_github(\"GRousselet/rogme\")\n\n\n# library(rogme)\n\n\nout <- rogme::shifthd(d, rt ~ group)\n\n\nrogme::plot_sf(out)\n\n[[1]]"
  },
  {
    "objectID": "pages/chapters/04_summarizing_data.html",
    "href": "pages/chapters/04_summarizing_data.html",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "",
    "text": "Note\n\n\n\nüëâ R Code f√ºr dieses Kapitel downloaden\nOb eine Variable als factor definiert ist, wird als Attribut gespeichert. Attribute werden aber in einem .csv. File nicht mitgespeichert; deshalb m√ºssen wir die Gruppierungsvariablen wieder als factor definieren."
  },
  {
    "objectID": "pages/chapters/04_summarizing_data.html#pro-versuchsperson",
    "href": "pages/chapters/04_summarizing_data.html#pro-versuchsperson",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Pro Versuchsperson",
    "text": "Pro Versuchsperson\n\ndata\n\n# A tibble: 1,440 √ó 9\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\ndata |> \n  group_by(ID, condition)\n\n# A tibble: 1,440 √ó 9\n# Groups:   ID, condition [27]\n   trial ID    cue   direction response    rt choice correct condition\n   <dbl> <fct> <fct> <fct>        <dbl> <dbl> <fct>    <dbl> <fct>    \n 1     0 JH    right right            1 0.714 right        1 valid    \n 2     1 JH    right right            1 0.627 right        1 valid    \n 3     2 JH    none  right            0 0.670 left         0 neutral  \n 4     3 JH    none  right            1 0.574 right        1 neutral  \n 5     4 JH    left  left             1 0.841 right        0 valid    \n 6     5 JH    none  right            1 0.668 right        1 neutral  \n 7     6 JH    none  left             1 1.12  right        0 neutral  \n 8     7 JH    left  left             0 0.640 left         1 valid    \n 9     8 JH    left  right            0 1.13  left         0 invalid  \n10     9 JH    none  right            1 1.03  right        1 neutral  \n# ‚Ä¶ with 1,430 more rows\n\n\n\naccuracy <- data |>\n    group_by(ID, condition) |>\n    summarise(N = n(),\n              ncorrect = sum(correct),\n              accuracy = mean(correct))\n\n\naccuracy\n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition     N ncorrect accuracy\n   <fct> <fct>     <int>    <dbl>    <dbl>\n 1 JH    invalid      16       13   0.812 \n 2 JH    neutral      80       66   0.825 \n 3 JH    valid        64       60   0.938 \n 4 NS    invalid      16       11   0.688 \n 5 NS    neutral      80       56   0.7   \n 6 NS    valid        64       58   0.906 \n 7 rh    invalid      16        2   0.125 \n 8 rh    neutral      80       64   0.8   \n 9 rh    valid        64       61   0.953 \n10 sb    invalid      16        1   0.0625\n# ‚Ä¶ with 17 more rows"
  },
  {
    "objectID": "pages/chapters/04_summarizing_data.html#visualisieren",
    "href": "pages/chapters/04_summarizing_data.html#visualisieren",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Visualisieren",
    "text": "Visualisieren\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Proportion correct\",\n    title = \"Accuracy per person/condition\"\n  ) +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)"
  },
  {
    "objectID": "pages/chapters/04_summarizing_data.html#√ºber-versuchsperson-aggregieren",
    "href": "pages/chapters/04_summarizing_data.html#√ºber-versuchsperson-aggregieren",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "√úber Versuchsperson aggregieren",
    "text": "√úber Versuchsperson aggregieren"
  },
  {
    "objectID": "pages/chapters/04_summarizing_data.html#ein-exkurs-√ºber-within-person-standardfehler",
    "href": "pages/chapters/04_summarizing_data.html#ein-exkurs-√ºber-within-person-standardfehler",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Ein Exkurs √ºber Within-person Standardfehler",
    "text": "Ein Exkurs √ºber Within-person Standardfehler\n\nlibrary(tidyverse)\n\ndfw <- tribble(\n ~subject, ~pretest, ~posttest,\n       1,   59.4,     64.5,\n       2,   46.4,     52.4,\n       3,   46.0,     49.7,\n       4,   49.0,     48.7,\n       5,   32.5,     37.4,\n       6,   45.2,     49.5,\n       7,   60.3,     59.9,\n       8,   54.3,     54.1,\n       9,   45.4,     49.6,\n      10,   38.9,     48.5) |>\n    mutate(subject = as.factor(subject))\n\n\ndfl <- dfw |>\n    pivot_longer(contains(\"test\"),\n                 names_to = \"condition\",\n                 values_to = \"value\") |>\n    mutate(condition = as_factor(condition))\n\n\ndflsum <- dfl |>\n    Rmisc::summarySEwithin(measurevar = \"value\",\n                               withinvars = \"condition\",\n                               idvar = \"subject\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\n\n\ndflsum |>\n    ggplot(aes(x = condition, y = value, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = value-ci, ymax = value+ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ylim(40,60)\n\n\n\n\n\n# Use a consistent y range\nymax <- max(dfl$value)\nymin <- min(dfl$value)\n\n\n# Plot the individuals\ndfl |>\n    ggplot(aes(x=condition, y=value, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\ndfNorm_long <- Rmisc::normDataWithin(data=dfl, idvar=\"subject\", measurevar=\"value\")\n?Rmisc::normDataWithin\n\ndfNorm_long |>\n    ggplot(aes(x=condition, y=valueNormed, colour=subject, group=subject)) +\n    geom_line() + geom_point(shape=21, fill=\"white\") +\n    ylim(ymin,ymax)\n\n\n\n\n\n# Instead of summarySEwithin, use summarySE, which treats condition as though it were a between-subjects variable\ndflsum_between <- Rmisc::summarySE(data = dfl, \n                                   measurevar = \"value\", \n                                   groupvars = \"condition\", \n                                   na.rm = FALSE, \n                                   conf.interval = .95)\ndflsum_between\n\n  condition  N value       sd       se       ci\n1   pretest 10 47.74 8.598992 2.719240 6.151348\n2  posttest 10 51.43 7.253972 2.293907 5.189179\n\n\n\n# Show the between-S CI's in red, and the within-S CI's in black\ndflsum_between |>\n    ggplot(aes(x=condition, y=value, group=1)) +\n    geom_line() +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), colour=\"red\") +\n    geom_errorbar(width=.1, aes(ymin=value-ci, ymax=value+ci), data=dflsum) +\n    geom_point(shape=21, size=3, fill=\"white\") +\n    ylim(ymin,ymax)"
  },
  {
    "objectID": "pages/chapters/04_summarizing_data.html#within-person-standardfehler",
    "href": "pages/chapters/04_summarizing_data.html#within-person-standardfehler",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Within-person Standardfehler",
    "text": "Within-person Standardfehler\n\naccuracy |> \n  ggplot(aes(x = condition, y = accuracy, colour = ID, group = ID)) +\n    geom_line() + \n  geom_point(shape=21, fill=\"white\")\n\n\n\n\nDer Standardfehler is definiert als: \\[SE = sd/ \\sqrt{n}\\]\nLeider gibt es in R keine Funktion, welche den Standardfehler berechnet (sch√§tzt); wir k√∂nnen aber ganz einfach selber eine Funktion definieren.\n\nse <- function(x) sd(x)/sqrt(length(x))\n\n\ndatasum <- data |>\n   group_by(condition) |> \n   summarise(N = n(),\n             ccuracy = mean(correct),\n             sd = sd(correct),\n             se = se(correct))\ndatasum\n\n# A tibble: 3 √ó 5\n  condition     N ccuracy    sd     se\n  <fct>     <int>   <dbl> <dbl>  <dbl>\n1 invalid     144   0.389 0.489 0.0408\n2 neutral     720   0.629 0.483 0.0180\n3 valid       576   0.825 0.381 0.0159\n\n\n\ndatasum_2 <- data |>\n    Rmisc::summarySE(measurevar = \"correct\",\n                              groupvars = \"condition\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_2\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.4891996 0.04076663 0.08058308\n2   neutral 720 0.6291667 0.4833637 0.01801390 0.03536613\n3     valid 576 0.8246528 0.3805943 0.01585810 0.03114686\n\n\n\ndatasum_3 <- data |>\n    Rmisc::summarySEwithin(measurevar = \"correct\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\ndatasum_3\n\n  condition   N   correct        sd         se         ci\n1   invalid 144 0.3888889 0.5773528 0.04811273 0.09510406\n2   neutral 720 0.6291667 0.5726512 0.02134145 0.04189901\n3     valid 576 0.8246528 0.4523391 0.01884746 0.03701827\n\n\n\np_accuracy <- datasum_3 |>\n    ggplot(aes(x = condition, y = correct, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = correct-se, ymax = correct+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\np_accuracy"
  },
  {
    "objectID": "pages/chapters/04_summarizing_data.html#pro-versuchsperson-1",
    "href": "pages/chapters/04_summarizing_data.html#pro-versuchsperson-1",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "Pro Versuchsperson",
    "text": "Pro Versuchsperson\nWir fassen die Daten pro Person pro Block mit Mittelwert, Median und Standarabweichung zusammen.\n\nfuns <- list(mean = mean, median = median, sd = sd)\n\nby_subj <- data %>%\n  drop_na(rt) |> \n  group_by(ID, condition) %>% \n  dplyr::summarise(across(rt, funs, .names = \"{.fn}\"))\n\n\nby_subj \n\n# A tibble: 27 √ó 5\n# Groups:   ID [9]\n   ID    condition  mean median     sd\n   <fct> <fct>     <dbl>  <dbl>  <dbl>\n 1 JH    invalid   0.775  0.739 0.163 \n 2 JH    neutral   0.799  0.733 0.202 \n 3 JH    valid     0.696  0.658 0.190 \n 4 NS    invalid   0.894  0.913 0.207 \n 5 NS    neutral   0.885  0.844 0.201 \n 6 NS    valid     0.738  0.715 0.191 \n 7 rh    invalid   0.423  0.389 0.151 \n 8 rh    neutral   0.525  0.503 0.0841\n 9 rh    valid     0.443  0.390 0.185 \n10 sb    invalid   0.376  0.341 0.0924\n# ‚Ä¶ with 17 more rows\n\n\nEinfachere Version:\n\nby_subj <- data |> \n  drop_na(rt) |> \n  group_by(ID, condition) |>  \n  dplyr::summarise(mean = mean(rt),\n                   median = median(rt),\n                   sd = sd(rt))\n\n\nby_subj |> \n  ggplot(aes(x = condition, y = mean, fill = condition)) +\n  geom_col() +\n  geom_line(aes(group = ID), size = 2) +\n  geom_point(size = 8) +\n  scale_fill_manual(\n    values = c(invalid = \"#9E0142\",\n    neutral = \"#C4C4B7\",\n    valid = \"#2EC762\")\n  ) +\n  labs(\n    x = \"Cue\",\n    y = \"Response time\") +\n  theme_linedraw(base_size = 28) +\n  facet_wrap(~ID)\n\n\n\n\n\nse <- function(x, ...) sd(x, ...)/sqrt(length(x))\n\nby_subj <- data %>% \n  group_by(ID, condition) %>% \n  summarise(mean = mean(rt, na.rm = TRUE), \n            median = median(rt, na.rm = TRUE), \n            sd = sd(rt, na.rm = TRUE), \n            se = se(rt, na.rm = TRUE))\n\n\nby_subj |> \n  ggplot(aes(condition, mean)) +\n  geom_line(aes(group = 1), linetype = 3) +    \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.2, size=1, color=\"blue\") +\n  geom_point(size = 2) +\n  facet_wrap(~ID, scales = \"free_y\")"
  },
  {
    "objectID": "pages/chapters/04_summarizing_data.html#√ºber-versuchsperson-aggregieren-1",
    "href": "pages/chapters/04_summarizing_data.html#√ºber-versuchsperson-aggregieren-1",
    "title": "Daten bearbeiten und zusammenfassen",
    "section": "√úber Versuchsperson aggregieren",
    "text": "√úber Versuchsperson aggregieren\n\nrtsum <- data |>\n  drop_na(rt) |> \n    Rmisc::summarySEwithin(measurevar = \"rt\",\n                               withinvars = \"condition\",\n                               idvar = \"ID\",\n                               na.rm = FALSE,\n                               conf.interval = 0.95)\nrtsum\n\n  condition   N        rt        sd         se         ci\n1   invalid 141 0.7055247 0.2204498 0.01856522 0.03670444\n2   neutral 710 0.7238269 0.2449543 0.00919297 0.01804870\n3     valid 568 0.6716487 0.2482698 0.01041717 0.02046095\n\n\n\np_rt <- rtsum |>\n    ggplot(aes(x = condition, y = rt, group = 1)) +\n    geom_line() +\n    geom_errorbar(width = .1, aes(ymin = rt-se, ymax = rt+se), colour=\"red\") +\n    geom_point(shape=21, size=3, fill=\"white\")\n\n\np_rt\n\n\n\n\n\nlibrary(patchwork)\n\n\np_accuracy / p_rt"
  },
  {
    "objectID": "pages/chapters/01_psychopy_experiments.html",
    "href": "pages/chapters/01_psychopy_experiments.html",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "",
    "text": "In dieser Sitzung erstellen wir ein perzeptuelles Entscheidungsexperiment, √§hnlich dem Experiment aus Mulder et al. (2012).\nDas Experiment ist eine Reaktionszeit (RT) Version eines Random-dot Motion Direction Discrimination Task, und wurde im Scanner und ausserhalb durchgef√ºhrt. Die beiden Version unterscheiden sich ganz stark in ihrem Timing. Wir implementieren hier die Scanner Version des Tasks.\nBias (Vorwissen) wurde durch einen Hinweisreiz angezeigt, in Form eines Pfeils oder eines neutralen Stimulus. Der Pfeil zeigte die wahrscheinlichere Bewegungsrichtung an. Vor und nach dem Cue wurde ein Fixationskreuz gezeigt. Alle weiteren Parameter k√∂nnen Sie dem Paper entnehmen (Mulder et al. 2012)."
  },
  {
    "objectID": "pages/chapters/01_psychopy_experiments.html#trial",
    "href": "pages/chapters/01_psychopy_experiments.html#trial",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Trial",
    "text": "Trial\nZun√§chst wird ein Fixationskreuz entweder f√ºr 100 ms, 350 ms, 800 ms oder 1200 ms angezeigt. Die tats√§chliche Dauer wird f√ºr jeden Versuch randomisiert. Eine solche Randomisierung kann nicht √ºber die Benutzeroberfl√§che vorgenommen werden, sondern erfordert ein kleines St√ºck Python-Code. Sehen Sie sich den Codeblock der Routine Fixation_pre_cue an, um zu erfahren, wie dies erreicht werden kann.\nAnschlie√üend wird f√ºr 1000 ms ein Hinweis pr√§sentiert. Dabei kann es sich entweder um einen Pfeil handeln, der nach rechts zeigt, einen Pfeil, der nach links zeigt, oder einen einfachen Kreis (f√ºr die Kontrollbedingung). Der Codeblock in der Cue-Routine legt den tats√§chlichen Hinweis f√ºr jeden Versuch auf der Grundlage der Schleifenvariablen cue fest.\nNach dem Cue wird ein weiteres Fixationskreuz pr√§sentiert - dieses Mal f√ºr entweder 3400ms, 4000ms, 4500ms oder 5000ms. Wie beim ersten Fixationskreuz wird die tats√§chliche Dauer zuf√§llig gew√§hlt.\nNach dem zweiten Fixationskreuz wird f√ºr 1500 ms der eigentliche Stimulus angezeigt: ein random dot kinematogram (RDK). Die Punkte bewegen sich entweder nach rechts oder nach links mit einem Koh√§renzniveau von 8%. Die Bewegungsrichtung eines einzelnen Versuchs wird durch die Schleifenvariable direction bestimmt und im Codeblock der Routine Dots festgelegt. Die Teilnehmer m√ºssen entscheiden, welche Richtung sie wahrnehmen, und k√∂nnen ihre Antwort durch Dr√ºcken der linken oder rechten Pfeiltaste auf der Tastatur eingeben.\nSchlie√ülich wird ein Feedback-Bildschirm angezeigt. Wenn der Teilnehmer innerhalb der ersten 100 ms geantwortet hat, wird der Hinweis ‚Äúzu schnell‚Äù angezeigt. Wurde w√§hrend des gesamten Stimulus keine Antwort erfasst, wird das Wort ‚Äúmiss‚Äù angezeigt. War die Antwort richtig, wird ‚Äú+5 Punkte‚Äù angezeigt, war sie falsch, wird ‚Äú+0 Punkte*‚Äù angezeigt."
  },
  {
    "objectID": "pages/chapters/01_psychopy_experiments.html#main_blocks_loop",
    "href": "pages/chapters/01_psychopy_experiments.html#main_blocks_loop",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "main_blocks_loop",
    "text": "main_blocks_loop\nMit loops in PsychoPy haben wir die M√∂glichkeit, eine oder mehrere Routinen zu wiederholen. In diesem Experiment wird dies genutzt, um denselben Versuch (wie oben beschrieben) mehrfach zu zeigen, aber jedes Mal mit anderen Werten f√ºr die loop variables. Eine Schleife wiederholt also einen Versuch einige Male, wobei die Schleifenvariablen bei jeder Wiederholung ge√§ndert werden. Der Versuch selbst wiederum liest diese Schleifenvariablen aus, um z.B. zu wissen, ob sich die Punkte nach rechts oder nach links bewegen sollen. Hier wird nur die main_blocks_loop erkl√§rt, aber das Prinzip gilt auch f√ºr die practice_block_loop.\nUm die verschiedenen Werte f√ºr die Schleifenvariablen zu definieren, m√ºssen wir eine einfache CSV-Datei erstellen:\ncue,direction\nleft,right\nleft,left\nnone,right\n...\nDiese CSV-Datei (die Bedingungsdatei) definiert die beiden loop Variablen cue und direction. Das Stichwort kann entweder left, right oder none, sein, w√§hrend die Richtung left oder right sein kann.\nIn der Benutzeroberfl√§che k√∂nnen wir die Variablen loopType und nReps f√ºr die Schleife angeben, wenn wir sie anklicken. Mit ersterer k√∂nnen wir steuern, ob wir z.B. die Zeilen in der Bedingungsdatei mischen oder sie sequentiell von oben nach unten ablaufen lassen wollen, w√§hrend die letztere definiert, wie oft jede Zeile der Bedingungsdatei wiederholt werden soll.\nF√ºr die main_blocks_loop haben wir eine Bedingungsdatei mit 80 Zeilen, die 40 neutralen Versuchen und 40 verzerrten Versuchen entsprechen. In der einen H√§lfte der neutralen Trials bewegen sich die Punkte nach rechts, in der anderen H√§lfte nach links. Bei den voreingenommenen Versuchen sind 32 der Hinweise g√ºltig (d.¬†h. sie stimmen mit der Bewegungsrichtung der Punkte √ºberein) und 16 ung√ºltig, wobei sich die Punkte sowohl bei g√ºltigen als auch bei ung√ºltigen Hinweisen in 50 % der Versuche nach rechts und in den anderen 50 % der Versuche nach links bewegen.\nDie Variable nReps wird auf 2 gesetzt, so dass alle diese Reihen zweimal durchlaufen werden (insgesamt 160 Versuche), und die Variable ‚ÄúloopType‚Äù wird auf random gesetzt, so dass die Versuche in zuf√§lliger Reihenfolge durchgef√ºhrt werden."
  },
  {
    "objectID": "pages/chapters/01_psychopy_experiments.html#daten",
    "href": "pages/chapters/01_psychopy_experiments.html#daten",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Daten",
    "text": "Daten\nWenn man die default-Einstellungen nicht √§ndert, speichert PsychoPy die Daten automatisch in einem trial-by-trial CSV File. Dieses CSV File erh√§lt einen Namen, der sich aus der Versuchspersonen-ID, dem Namen des Experiments, und dem aktuellen Datum inkl. Uhrzeit zusammensetzt. So ist es m√∂glich, mit derselben Versuchspersonen-ID beliebig oft das Experiment zu wiederholen. Die CSV Files werden in einem Ordner mit dem Name data abgelegt."
  },
  {
    "objectID": "pages/chapters/01_psychopy_experiments.html#degrees-of-visual-angle",
    "href": "pages/chapters/01_psychopy_experiments.html#degrees-of-visual-angle",
    "title": "Verhaltensexperiment mit PsychoPy",
    "section": "Degrees of Visual Angle",
    "text": "Degrees of Visual Angle\nOftmals werden Gr√∂ssenangaben von Stimuli noch in Pixel oder Zentimeter, sondern in degrees of visual angle gemacht. Dies hat den Vorteil, dass die Angaben nicht vom Monitor selber oder der Entferung vom Monitor abh√§ngig sind. degrees of visual angle gibt die wahrgenommene Gr√∂sse des Stimulus an, und ber√ºcksichtigt die Gr√∂sse des Monitors und des Stimulus, und die Entfernung der Versuchsperson vom Monitor. Weitere Informationen dazu finden Sie auf der Website von üëâ OpenSesame. √úblicherweise entspricht ein degrees of visual angle etwa einem cm bei einer Entfernung von 57 cm vom Monitor.\nZur Umrechnung zwischen cm und degrees of visual angle finden Sie unter diesem üëâ Link mehr Information.\n\nOpenSesame ist ein weiteres, Python-basierendes Programm f√ºr die Erstellung behaviouraler Experimente."
  },
  {
    "objectID": "pages/chapters/05_signal_detection_i.html",
    "href": "pages/chapters/05_signal_detection_i.html",
    "title": "Signal Detection Theory: I",
    "section": "",
    "text": "Note\n\n\n\nüëâ R Code f√ºr dieses Kapitel downloaden"
  },
  {
    "objectID": "pages/chapters/05_signal_detection_i.html#parameter-recovery-1",
    "href": "pages/chapters/05_signal_detection_i.html#parameter-recovery-1",
    "title": "Signal Detection Theory: I",
    "section": "Parameter recovery",
    "text": "Parameter recovery\nWe can now attempt to recover the known parameters c and d' from the observed hit and false alarm rates.\n\nyes_observer <- yes_observer |>\n    mutate(hit_rate = Hit/(Hit + Miss),\n           fa_rate = FA/(FA + CR))\n\nyes_observer <- yes_observer |>\n    mutate(zhr = qnorm(hit_rate),\n           zfa = qnorm(fa_rate))\n\nyes_observer <- yes_observer |>\n    mutate(dprime = zhr - zfa,\n           k = - zfa,\n           c = -0.5 * (zhr + zfa)) |>\n    mutate(across(c(dprime, c), round, 2))\n\n\nyes_observer \n\n# A tibble: 1 √ó 11\n    Hit  Miss    FA    CR hit_rate fa_rate   zhr   zfa dprime      k     c\n  <int> <dbl> <int> <dbl>    <dbl>   <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>\n1    92     8    74    26     0.92    0.74  1.41 0.643   0.76 -0.643 -1.02\n\n\nFor the biased observer, the valuues we used were \\(d' = 1\\) and \\(c = -1\\). Are we able to recover these?\n\nyes_observer |> pull(c, dprime)\n\n 0.76 \n-1.02 \n\n\n\n\n\n\n\n\nNote\n\n\n\nWhy is it seemingly difficult to recover theses parameters?"
  },
  {
    "objectID": "pages/chapters/08_response_times_ii.html",
    "href": "pages/chapters/08_response_times_ii.html",
    "title": "Reaktionszeiten: II",
    "section": "",
    "text": "Hierarchical Shift Function\nWir schauen uns Daten aus einem Lexical Decision Task (Wagenmakers and Brown 2007) an, bei dem Versuchspersonen W√∂rter als entweder word oder non-word klassifizieren mussten. Es ist bekannt, dass W√∂rter welche h√§ufiger vorkommen schneller klassifiziert werden k√∂nnen, als seltene W√∂rter. In diesem Experiment mussten Versuchspersonen diesen Task unter zwei Bedingungen durchf√ºhren. In der speed Bedingung mussten sie sich so schnell wie m√∂glich entscheiden, in der accuracy Bedingung mit so wenig Fehler wie m√∂glich.\nHier untersuchen wir also den Unterschied in der Reaktionszeit zwischen zwei ‚Äúwithin‚Äù Bedingungen. Die Daten befinden sich im Package rtdists, welches zuerst installiert werden sollte.\n\nlibrary(tidyverse)\nlibrary(rtdists)\nlibrary(viridis)\n\ndata(speed_acc) \n\nspeed_acc <- speed_acc |>\n  as_tibble()\n\n\ndf_speed_acc <- speed_acc |> \n   # zwischen 180 ms and 3000 ms\n  filter(rt > 0.18, rt < 3) |> \n   # zu Character konvertieren (damit filter funktioniert)\n  mutate(across(c(stim_cat, response), as.character)) |> \n  # Korrekte Antworten\n  filter(response != 'error', stim_cat == response) |> \n  # wieder zu Factor konvertieren\n  mutate(across(c(stim_cat, response), as_factor))\n\n\ndf_speed_acc\n\n# A tibble: 27,936 √ó 9\n   id    block condition stim  stim_cat frequency   response    rt censor\n   <fct> <fct> <fct>     <fct> <fct>    <fct>       <fct>    <dbl> <lgl> \n 1 1     1     speed     5015  nonword  nw_low      nonword  0.7   FALSE \n 2 1     1     speed     6481  nonword  nw_very_low nonword  0.46  FALSE \n 3 1     1     speed     3305  word     very_low    word     0.455 FALSE \n 4 1     1     speed     4468  nonword  nw_high     nonword  0.773 FALSE \n 5 1     1     speed     1047  word     high        word     0.39  FALSE \n 6 1     1     speed     5036  nonword  nw_low      nonword  0.603 FALSE \n 7 1     1     speed     1111  word     high        word     0.435 FALSE \n 8 1     1     speed     6561  nonword  nw_very_low nonword  0.524 FALSE \n 9 1     1     speed     1670  word     high        word     0.427 FALSE \n10 1     1     speed     6207  nonword  nw_very_low nonword  0.456 FALSE \n# ‚Ä¶ with 27,926 more rows\n\n\nWir schauen uns vier Versuchspersonen grafisch an:\n\ndata_plot <- df_speed_acc |> \n  filter(id %in% c(1, 8, 11, 15))\n\ndata_plot |> \n  ggplot(aes(x = rt)) + \n    geom_histogram(aes(fill = condition), alpha = 0.5, bins = 60) + \n    facet_wrap(~id) +\n    coord_cartesian(xlim=c(0, 1.6)) +\n    scale_fill_viridis(discrete = TRUE, option = \"E\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSchauen Sie sich alle Vpn an.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWas w√ºrden Sie anhand der Histogramme erwarten?\n\n\n\n\n\n\n\n\nNote\n\n\n\nBerechnen Sie nun die Differenzen der Dezile zwischen den Bedingungen f√ºr jede Versuchsperson.\n\n\n\nout_speed_acc <- rogme::hsf_pb(df_speed_acc, rt ~ condition + id)\n\n\np_speed_acc <- rogme::plot_hsf_pb(out_speed_acc, interv = \"ci\")\np_speed_acc\n\n\n\n\nIn dieser Grafik sehen wir auf der X-Achse die Dezile der accuracy Bedingung und auf der Y-Achse die Differenz accuracy - speed. Die Differenz ist bei jedem Dezil positiv und scheint steig gr√∂sser zu werden. Die accuracy Bedingung f√ºhrt also zu l√§ngeren und variableren Reaktionszeiten. Die Bedingungen unterscheiden sich im Median, aber wenn wir nur das ber√ºcksichtigt h√§tten, w√ºrden wir verpassen, dass sich die Verteilungen sehr stark am rechten Ende der Verteilung unterscheiden.\nZum Vergleich berechnen wir noch Bedingungsmittelwerte der Median Reaktionszeiten.\n\nby_subject <- df_speed_acc |> \n  group_by(id, condition) |> \n  summarise(mean = median(rt))\n\nagg <- Rmisc::summarySEwithin(by_subject,\n                       measurevar = \"mean\",\n                       withinvars = \"condition\",\n                       idvar = \"id\",\n                       na.rm = FALSE,\n                       conf.interval = .95)\n\n\nagg |> \n  ggplot(aes(condition, mean, fill = condition)) +\n  geom_col(alpha = 0.8) +\n  geom_line(aes(group = 1), linetype = 3) +   \n  geom_errorbar(aes(ymin = mean-se, ymax = mean+se),\n                width = 0.1, size=1, color=\"black\") +\n  scale_fill_viridis(discrete=TRUE, option=\"cividis\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nReferences\n\nWagenmakers, Eric-Jan, and Scott Brown. 2007. ‚ÄúOn the Linear Relation Between the Mean and the Standard Deviation of a Response Time Distribution.‚Äù Psychological Review 114 (3): 830‚Äì41. https://doi.org/10.1037/0033-295X.114.3.830.\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis2022,\n  author = {Andrew Ellis},\n  title = {Reaktionszeiten: {II}},\n  date = {2022-04-12},\n  url = {https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/chapters/08_response_times_ii.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. 2022. ‚ÄúReaktionszeiten: II.‚Äù April 12, 2022.\nhttps://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/chapters/08_response_times_ii.html."
  },
  {
    "objectID": "pages/chapters/03_data_cleaning.html",
    "href": "pages/chapters/03_data_cleaning.html",
    "title": "Data cleaning",
    "section": "",
    "text": "Note\n\n\n\nüëâ R Code f√ºr dieses Kapitel downloaden\nNun wollen wir versuchen, einzelne Trials, zu identifizieren, in denen Versuchpersonen nicht aufgepasst haben, oder einfach geraten wurde.\nAm h√§ufigsten werden die folgenden beiden Kriterien verwendet, um entweder einzelne Datenpunkte, oder Versuchspersonen, auszuschliessen:\nNun ist in Experimenten, in denen ein Bias erzeugt wird, etwas heikel, Trials oder Versuchspersonen aufgrund der Anzahl korrekter Antworten auszuschliessen - wir haben ja die Korrektheit der Antworten experimentell manipuliert.\nDeswegen richten wir hier unseren Fokus auf die Reaktionszeiten. Wir gehen davon aus, dass Reaktionszeiten, die zu schnell oder yu langsam waren, aufgrund von Rateprozessen zustande kamen. Was genau zu schnell oder zu langsam heisst, ist schwierig zu beantworten, und h√§ngt stark vom jeweiligen Task ab. Deshalb ist es wichtig, sich a priori Gedanken dar√ºber zu machen, welche Kriterien angewandt werden sollen."
  },
  {
    "objectID": "pages/chapters/03_data_cleaning.html#eigenschaften-von-reaktionszeiten",
    "href": "pages/chapters/03_data_cleaning.html#eigenschaften-von-reaktionszeiten",
    "title": "Data cleaning",
    "section": "Eigenschaften von Reaktionszeiten",
    "text": "Eigenschaften von Reaktionszeiten\nDie wichtigsten Merkmale von Reaktionszeiten sind\n\nSie sind rechtsschief\nSie sind nicht normalverteilt\nStreuung (Standardabweichung) steigt ungef√§hr linear mit wachsendem Mittelwert (Wagenmakers and Brown 2007)\n\n\nDie Rechtschiefe ist eine nat√ºrliche Konsequenz der Tatsache, dass es viele M√∂glichkeiten gibt, langsamer zu werden, aber nur wenige M√∂glichkeiten, schneller zu werden. Reaktionszeiten k√∂nnen nicht negativ sein Ausserdem gibt es eine Untergrenze, welche durch unsere Physiologie bestimmt ist. Schellere Reaktionszeiten als 200 Millisekunden sind kaum m√∂glich.\nDie Konsequenz daraus ist, dass Reaktionszeiten nicht normalverteilt sind. In folgender Grafik sind zwei Verteilungen dargestellt. Die gelbe Verteilung ist eine Normalverteilung mit \\(\\mu = 1\\) und \\(\\sigma = 0.4\\), w√§hrend die graue Verteilung eine LogNormal Verteilung darstellt.\n\nEine LogNormal-Verteilung bedeutet, dass der Logarithmus einer Zufallsvariablen normalverteilt ist.\n\n\n\n\n\nObwohl die Normalverteilung so aussieht, als k√∂nne sie Reaktionszeiten repr√§sentieren, ist der Wertebereich von \\([-\\Inf, \\Inf]\\) nicht daf√ºr geeignet. Ausserdem erlaubt die Normalverteilung keine extremen Werte, und ist nicht asymmetrisch."
  },
  {
    "objectID": "pages/exercises/exercise_01.html",
    "href": "pages/exercises/exercise_01.html",
    "title": "√úbung 1",
    "section": "",
    "text": "Reusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis2022,\n  author = {Andrew Ellis},\n  title = {√úbung 1},\n  date = {2022-02-22},\n  url = {https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/exercises/exercise_01.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. 2022. ‚Äú√úbung 1.‚Äù February 22, 2022. https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/exercises/exercise_01.html."
  },
  {
    "objectID": "pages/exercises/exercise_02.html",
    "href": "pages/exercises/exercise_02.html",
    "title": "√úbung 2",
    "section": "",
    "text": "Reusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{ellis2022,\n  author = {Andrew Ellis},\n  title = {√úbung 2},\n  date = {2022-03-01},\n  url = {https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/exercises/exercise_02.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAndrew Ellis. 2022. ‚Äú√úbung 2.‚Äù March 1, 2022. https://kogpsy.github.io/neuroscicomplab_fs22_quarto//pages/exercises/exercise_02.html."
  },
  {
    "objectID": "pages/exercises/exercise_04.html",
    "href": "pages/exercises/exercise_04.html",
    "title": "√úbung 4",
    "section": "",
    "text": "In dieser √úbung berechnen aus den Daten von 15 Versuchspersonen aus dem PsychoPy Experiment die Signal Detection Kennzahlen \\(d'\\), \\(k\\) und \\(c\\). Anschliessen berechnen Sie Mittelwerte der drei Bedingungen f√ºr \\(d'\\) und \\(c\\) unter Ber√ºcksichtigung der Messwiederholung."
  },
  {
    "objectID": "pages/exercises/exercise_04.html#variablen-bearbeiten",
    "href": "pages/exercises/exercise_04.html#variablen-bearbeiten",
    "title": "√úbung 4",
    "section": "Variablen bearbeiten",
    "text": "Variablen bearbeiten\nZu factor konvertieren, etc.\n\nd <- d |>\n    select(ID, condition, cue, direction, choice) |>\n    mutate(across(where(is.character), ~as_factor(.)),\n           cue = fct_relevel(cue, \"left\", \"none\", \"right\")) |>\n    drop_na()\n\n\nsdt <- d |>\n    mutate(type = case_when(\n        direction == \"right\" & choice == \"right\" ~ \"Hit\",\n        direction == \"right\" & choice == \"left\" ~ \"Miss\",\n        direction == \"left\" & choice == \"left\" ~ \"CR\",\n        direction == \"left\" & choice == \"right\" ~ \"FA\"))\n\nF√ºr jede Vpn in jeder der drei cue Bedingungen die verschiedenen Antworttypen z√§hlen.\n\nsdt_summary <- sdt |>\n    group_by(ID, cue) |>\n    count(type)\n\n\nsdt_summary\n\n# A tibble: 170 √ó 4\n# Groups:   ID, cue [45]\n   ID     cue   type      n\n   <fct>  <fct> <chr> <int>\n 1 chch04 left  CR       29\n 2 chch04 left  FA        3\n 3 chch04 left  Hit       7\n 4 chch04 left  Miss      1\n 5 chch04 none  CR       38\n 6 chch04 none  FA        2\n 7 chch04 none  Hit      34\n 8 chch04 none  Miss      6\n 9 chch04 right CR        5\n10 chch04 right FA        3\n# ‚Ä¶ with 160 more rows"
  },
  {
    "objectID": "pages/exercises/exercise_04.html#von-wide-zu-long-konvertieren",
    "href": "pages/exercises/exercise_04.html#von-wide-zu-long-konvertieren",
    "title": "√úbung 4",
    "section": "Von wide zu long konvertieren",
    "text": "Von wide zu long konvertieren\n\nsdt_summary <- sdt_summary |>\n    pivot_wider(names_from = type, values_from = n)\n\n\nsdt_summary\n\n# A tibble: 45 √ó 6\n# Groups:   ID, cue [45]\n   ID     cue      CR    FA   Hit  Miss\n   <fct>  <fct> <int> <int> <int> <int>\n 1 chch04 left     29     3     7     1\n 2 chch04 none     38     2    34     6\n 3 chch04 right     5     3    25     7\n 4 chmi14 left     21    10     5     3\n 5 chmi14 none     18    19    29     7\n 6 chmi14 right     3     4    26     4\n 7 J      left     19    12     5     3\n 8 J      none     23    16    33     6\n 9 J      right     6     2    20    12\n10 jh     left     32    NA     5     3\n# ‚Ä¶ with 35 more rows"
  },
  {
    "objectID": "pages/exercises/exercise_04.html#funktionen-definieren",
    "href": "pages/exercises/exercise_04.html#funktionen-definieren",
    "title": "√úbung 4",
    "section": "Funktionen definieren",
    "text": "Funktionen definieren\n\nreplace_NA <- function(x) {\n    x = ifelse(is.na(x), 0, x)\n    x\n}\n\ncorrect_zero_one <- function(x) {\n    if (identical(x, 0)) {\n        x = x + 0.001\n    } else if (identical(x, 1)) {\n        x = x - 0.001\n    }\n    x\n}"
  },
  {
    "objectID": "pages/exercises/exercise_04.html#nas-ersetzen",
    "href": "pages/exercises/exercise_04.html#nas-ersetzen",
    "title": "√úbung 4",
    "section": "NAs ersetzen",
    "text": "NAs ersetzen\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(Hit, Miss, FA, CR), replace_NA))"
  },
  {
    "objectID": "pages/exercises/exercise_04.html#hit-rate-und-false-alarm-rate-berechnen",
    "href": "pages/exercises/exercise_04.html#hit-rate-und-false-alarm-rate-berechnen",
    "title": "√úbung 4",
    "section": "Hit Rate und False Alarm Rate berechnen",
    "text": "Hit Rate und False Alarm Rate berechnen\n\nsdt_summary <- sdt_summary |>\n    mutate(hit_rate = ___,\n           fa_rate = ___)"
  },
  {
    "objectID": "pages/exercises/exercise_04.html#werte-0-und-1-korrigieren",
    "href": "pages/exercises/exercise_04.html#werte-0-und-1-korrigieren",
    "title": "√úbung 4",
    "section": "Werte 0 und 1 korrigieren",
    "text": "Werte 0 und 1 korrigieren\n\nsdt_summary <- sdt_summary |>\n    mutate(across(c(hit_rate, fa_rate), correct_zero_one))"
  },
  {
    "objectID": "pages/exercises/exercise_04.html#z-transformation",
    "href": "pages/exercises/exercise_04.html#z-transformation",
    "title": "√úbung 4",
    "section": "Z-Transformation",
    "text": "Z-Transformation\n\nsdt_summary <- sdt_summary |>\n    mutate(zhr = qnorm(hit_rate),\n           zfa = qnorm(fa_rate))\n\n\nsdt_summary\n\n# A tibble: 45 √ó 10\n# Groups:   ID, cue [45]\n   ID     cue      CR    FA   Hit  Miss hit_rate fa_rate   zhr     zfa\n   <fct>  <fct> <int> <dbl> <int> <dbl>    <dbl>   <dbl> <dbl>   <dbl>\n 1 chch04 left     29     3     7     1    0.875  0.0938 1.15  -1.32  \n 2 chch04 none     38     2    34     6    0.85   0.05   1.04  -1.64  \n 3 chch04 right     5     3    25     7    0.781  0.375  0.776 -0.319 \n 4 chmi14 left     21    10     5     3    0.625  0.323  0.319 -0.460 \n 5 chmi14 none     18    19    29     7    0.806  0.514  0.862  0.0339\n 6 chmi14 right     3     4    26     4    0.867  0.571  1.11   0.180 \n 7 J      left     19    12     5     3    0.625  0.387  0.319 -0.287 \n 8 J      none     23    16    33     6    0.846  0.410  1.02  -0.227 \n 9 J      right     6     2    20    12    0.625  0.25   0.319 -0.674 \n10 jh     left     32     0     5     3    0.625  0.001  0.319 -3.09  \n# ‚Ä¶ with 35 more rows"
  },
  {
    "objectID": "pages/exercises/exercise_04.html#sdt-kennzahlen-berechnen",
    "href": "pages/exercises/exercise_04.html#sdt-kennzahlen-berechnen",
    "title": "√úbung 4",
    "section": "SDT Kennzahlen berechnen",
    "text": "SDT Kennzahlen berechnen\n\nsdt_summary <- sdt_summary |>\n    mutate(dprime = ___,\n           k = ___,\n           c = ___) |>\n    mutate(across(c(dprime, k, c), round, 2))"
  },
  {
    "objectID": "pages/exercises/exercise_04.html#variablen-ausw√§hlen",
    "href": "pages/exercises/exercise_04.html#variablen-ausw√§hlen",
    "title": "√úbung 4",
    "section": "Variablen ausw√§hlen",
    "text": "Variablen ausw√§hlen\n\nsdt_final <- sdt_summary |>\n    select(ID, cue, dprime, k, c)\n\nIm finalen Datensatz haben wir nun d', k und c f√ºr jede Person in jeder Bedingung.\n\nsdt_final\n\n# A tibble: 45 √ó 5\n# Groups:   ID, cue [45]\n   ID     cue   dprime     k     c\n   <fct>  <fct>  <dbl> <dbl> <dbl>\n 1 chch04 left    2.47  1.32  0.08\n 2 chch04 none    2.68  1.64  0.3 \n 3 chch04 right   1.1   0.32 -0.23\n 4 chmi14 left    0.78  0.46  0.07\n 5 chmi14 none    0.83 -0.03 -0.45\n 6 chmi14 right   0.93 -0.18 -0.65\n 7 J      left    0.61  0.29 -0.02\n 8 J      none    1.25  0.23 -0.4 \n 9 J      right   0.99  0.67  0.18\n10 jh     left    3.41  3.09  1.39\n# ‚Ä¶ with 35 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nWir erwarten, dass sich d' zwischen den Bedingungen nicht unterscheidet. k und c (bias) sollte sich hingegen zwischen den cue Bedingungen unterscheiden. Uns interessiert hier vor allem c: in der neutralen Bedingung sollte c etwa 0 sein, in der ‚Äòleft‚Äô Bedingung sollte \\(c > 0\\) sein, und in der ‚Äòright‚Äô Bedingung sollte \\(c < 0\\) sein.\nVersuchen Sie die untenstehende Grafiken f√ºr d' und c zu reproduzieren.\n\n\n\n\n\n\n\nSie brauchen zuerst eine (separate) Zusammenfassung der d' und c Werte, welche die Messwiederholung respektiert. Sie k√∂nnen dazu die Funktion summarySEwithin aus dem Rmisc Package verwenden.\nDie Funktion braucht die Argumente measurevar, withinvars und idvar.\n\n\n\n\n\n\nArgument\nBeschreibung\n\n\n\nmeasurevar\nVariable, f√ºr welche eine Messwiederholung vorliegt\n\n\nwithinvars\nMesswiederholung\n\n\nidvar\nIdentit√§t der messwiederholten Einheit\n\n\n\n\ncs <- sdt_final |>\n    select(ID, cue, c) |>\n    ___\n\n\ndprimes <- sdt_final |>\n    select(ID, cue, ___) |>\n    ___\n\nWenn Sie, wie ich, die Datens√§tze mit den Mittelwerten, Standardfehlern und \\(95%\\) Konfidenzintervallen primes und cs genannt haben, k√∂nnen Sie die Plots beispielsweise so erstellen.\n\ncs |>\n    ggplot(aes(x = cue, y = c, group = 1)) + \n    geom_hline(yintercept = 0, \n               linetype = \"dashed\",\n               color = \"grey60\") +\n    geom_line() +\n    geom_errorbar(width = 0.1, aes(ymin = c - ci,\n                                   ymax = c + ci)) +\n    geom_point(shape = 21, size = 3, fill = \"white\") +\n    ggtitle(\"c (bias)\")\n\nFalls Sie wollen, k√∂nnen Sie die individuellen c Sch√§tzungen dem Plot hinzuf√ºgen, mit folgendem Code:\ngeom_jitter(aes(cue, c), data = sdt_final, width = 0.05)"
  },
  {
    "objectID": "pages/exercises/exercise_03.html",
    "href": "pages/exercises/exercise_03.html",
    "title": "√úbung 3",
    "section": "",
    "text": "Note\n\n\n\nDie Aufgaben, die Sie bearbeiten sollen, finden Sie in einem gelben Kasten. Optionale Aufgaben sind in orangen K√§sten.\nIn diesem File finden Sie Beispielscode. Manche Zeilen enthalten ___. Hier m√ºssen Sie den Code vervollst√§ndigen.\nLaden Sie bitte Ihre L√∂sung als ZIP File bis Freitag, 25.03.2022, um 00:00 Uhr, in den Order f√ºr √úbung 3 auf ILIAS. Das ZIP File sollte ein R Skript enthalten, sowie den bereinigten Datensatz.\nNennen Sie Ihr File Matrikelnummer_Nachname_uebung-3.zip."
  },
  {
    "objectID": "pages/exercises/exercise_03.html#aufgaben",
    "href": "pages/exercises/exercise_03.html#aufgaben",
    "title": "√úbung 3",
    "section": "Aufgaben",
    "text": "Aufgaben\n\n\n\n\n\n\nNote\n\n\n\nAufgabe 1\n\nSpeichern Sie das CSV File in Ihren Projektordner.\nLesen Sie das CSV File ein. Per Konvention verwenden wir den Variablennamen d f√ºr den Datensatz.\n√úberpr√ºfen Sie, ob alle Variablen vorhanden sind. Verwenden Sie z.B. die Funktion glimpse().\nKonvertieren Sie die Gruppierungsvariablen subject und condition zu Faktoren.\n\n\n\n\nlibrary(tidyverse)\n\n\nd <- read_csv(\"___\")\n\nSchauen Sie sich die Variablen an:\n\nglimpse(d)\n\nKonvertieren Sie die Gruppierungsvariablen zu Faktoren:\n\nd <- d |>\n    mutate(___ = as_factor(___),\n           ___ = as_factor(___))\n\n\n\n\n\n\n\nNote\n\n\n\nAufgabe 2\nGibt es Versuchspersonen die in einer der Bedingungen Reaktionszeiten hat, welche mehr als zwei Standardabweichungen √ºber dem Bedingungsmittelwert liegen?\n\n\n\n# summary stats (means) for subjects/conditions\nsum_stats_participants <- d |>\n    group_by(___, ___) |>\n    dplyr::summarise(\n        mean_P = mean(___))\n\n\n# summary stats (means and SDs) for conditions\nsum_stats_conditions <- d |>\n    group_by(___) |>\n    dplyr::summarise(\n        mean_C = mean(__),\n        sd_C = sd(___))\n\n\nsum_stats_participants <-\n    full_join(\n        sum_stats_participants,\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(outlier_P = ___)\n\n\n# show outlier participants\nsum_stats_participants |>\n    filter(outlier_P == 1) |>\n    show()\n\n\nexcluded <- sum_stats_participants |>\n    filter(outlier_P == 1)\n\nexcluded\n\n\nd_cleaned <- d |>\n    filter(!(subject %in% excluded$subject)) |>\n    mutate(subject = fct_drop(subject))\n\n\n\n\n\n\n\nNote\n\n\n\nAufgabe 3\n\nGibt es einzelne Trials, in denen Versuchpersonen l√§nger als 4 Standardabweichungen √ºber dem Bedingungsmittelwert gebraucht haben, um zu Antworten?\nGibt es einzelne Trials, in denen Versuchpersonen zu schnell (unter 100 ms) geantwortet haben?\nSpeichern Sie den bearbeiteten Datensatz als CSV File.\n\n\n\n\nd_cleaned <- d_cleaned |>\n    full_join(\n        sum_stats_conditions,\n        by = \"condition\") |>\n    mutate(\n        trial_type = case_when(\n            ___ > ___ ~ \"too slow\",\n            ___ < ___ ~ \"too fast\",\n            TRUE ~ \"OK\") |>\n            factor(levels = c(\"OK\", \"too fast\", \"too slow\")))\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt, color = trial_type, shape = trial_type)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\nd_cleaned |>\n    filter(trial_type != \"OK\")\n\n\nd_cleaned <- d_cleaned |>\n    filter(trial_type == \"OK\") |>\n    select(subject, trial_num, condition, signal_present, correct, rt)\n\n\nd_cleaned |>\n    ggplot(aes(x = trial_num, y = rt)) +\n    geom_point(alpha = 0.6) +\n    facet_grid(~condition) +\n    scale_color_manual(values = c(\"gray70\", \"red\", \"steelblue\"))\n\n\nd_cleaned |> write_csv(___)\n\n\n\n\n\n\n\nTip\n\n\n\nOptionale Aufgabe\nDie Aufgaben oben bieten lediglich Voschl√§ge, wie man ‚ÄúAusreisser‚Äù identifizieren k√∂nnte. Wenn Sie andere Voschl√§ge haben, k√∂nnen Sie den Code anpassen, oder selber Code schreiben. K√∂nnen Sie Ihr Vorgehen begr√ºnden?"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-cognitive-neuroscience",
    "href": "slides/01_introduction.html#model-based-cognitive-neuroscience",
    "title": "1. Sitzung",
    "section": "(Model-based) Cognitive Neuroscience",
    "text": "(Model-based) Cognitive Neuroscience\n\n\nWas heisst Model-based Neuroscience?\nWelche Kenntnisse brauchen wir, um Experiment durchzuf√ºhren und Daten auszuwerten?\nWelche Programmiertechniken/sprachen brauchen wir?"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-beispiel",
    "href": "slides/01_introduction.html#model-based-neuroscience-beispiel",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience: Beispiel",
    "text": "Model-based Neuroscience: Beispiel\nMulder, M. J., Wagenmakers, E.-J., Ratcliff, R., Boekel, W., & Forstmann, B. U. (2012). Bias in the Brain: A Diffusion Model Analysis of Prior Probability and Potential Payoff. Journal of Neuroscience, 32(7), 2335‚Äì2343.\nüëâ https://www.jneurosci.org/content/32/7/2335\nIn dieser Studie geht es darum, den Einfluss von Vorwissen (prior knowledge) auf eine simple perzeptuelle Entscheidung zu untersuchen.\n\nAls Task haben die Autoren ein Random Dot Motion Experiment benutzt.\nF√ºr die Datenanalyse wurde unter anderem ein Diffusion Decision Model verwendet."
  },
  {
    "objectID": "slides/01_introduction.html#diffusion-decision-model",
    "href": "slides/01_introduction.html#diffusion-decision-model",
    "title": "1. Sitzung",
    "section": "Diffusion Decision Model",
    "text": "Diffusion Decision Model"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience",
    "href": "slides/01_introduction.html#model-based-neuroscience",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\n\n√úberfliegen Sie das Paper, und achten Sie dabei darauf, welche Skills Sie ben√∂tigen, um eine solche Studie durchzuf√ºhren.\n\nWelches theoretische Wissen brauchen Sie?\nWelche Programmierkenntnisse brauchen Sie?\n\nf√ºr das Experiment\nf√ºr die Datenanalyse\n\nWelche statistischen Verfahen brauchen Sie, um die Daten auszuwerten?\nWarum wurde das Experiment im Scanner und ausserhalb des Scanners durchgef√ºhrt?\nWas kann man mit einer solchen Studie herausfinden?"
  },
  {
    "objectID": "slides/01_introduction.html#vorwissen",
    "href": "slides/01_introduction.html#vorwissen",
    "title": "1. Sitzung",
    "section": "Vorwissen",
    "text": "Vorwissen\nEs wurden zwei verschiedene Typen von Vorwissen benutzt.\n\nA-Priori Wahrscheinlichkeit, dass die Punktwolke sich nach rechts oder nach links bewegte.\nAsymmetrische Belohnung f√ºr korrekte links/rechts Entscheidungen."
  },
  {
    "objectID": "slides/01_introduction.html#diffusion-decision-model-1",
    "href": "slides/01_introduction.html#diffusion-decision-model-1",
    "title": "1. Sitzung",
    "section": "Diffusion Decision Model",
    "text": "Diffusion Decision Model"
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-1",
    "href": "slides/01_introduction.html#model-based-neuroscience-1",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\n\n\nSchematische Darstellung der erwarteten Resultate.\n\nStarting point: korrekte und inkorrekte RTs unterschieden sich.\nDrift rate: korrekte und inkorrekte RTs sind sich √§hnlich.\n\n\n\nTats√§chliche Resultate: Quantifizierung des Bias anhand des DDM."
  },
  {
    "objectID": "slides/01_introduction.html#model-based-neuroscience-2",
    "href": "slides/01_introduction.html#model-based-neuroscience-2",
    "title": "1. Sitzung",
    "section": "Model-based Neuroscience",
    "text": "Model-based Neuroscience\nBOLD Responses der Areale welche besonder stark sowohl auf die ‚Äúprior probability‚Äù als auch auf die ‚Äúpayoff‚Äù Manipulation reagierten.\n\n\n\nright MedFG (right medial frontal gyrus)\nACG (anterior cingulate cortex)\nSFG (superior frontal gyrus)\nleft middle temporal gyrus\nIPS (intra-parietal sulcus).\n\n\n\n\n\nDiese Areale sollen eine besondere Rolle in der Verarbeitung von Bias im Entscheidungsverhalten haben."
  },
  {
    "objectID": "slides/01_introduction.html#wichtige-skills",
    "href": "slides/01_introduction.html#wichtige-skills",
    "title": "1. Sitzung",
    "section": "Wichtige Skills",
    "text": "Wichtige Skills\n\n\n\nTheorien √ºber Entscheidungsverhalten\nExperimente programmieren\n\nTiming (inside/outside scanner)\n\nData cleaning and manipulation (data wrangling)\nStatistische Verfahren f√ºr messwiederholte Daten\n\nPsychometric curve\nBinary choices / Reaktionszeiten\nrepeated-measures ANOVA\n\n\n\n\nGrafische Darstellung der Resultate\nKognitive Prozessmodelle\n\nfit Diffusion Decision Model (DDM)\n\nAuswertung von fRMI Daten\n\n\n\n\nMit diesen Themen (ausser der Analyse von fMRI Daten) besch√§ftigen wir uns in diesem Kurs.\n\n\n\nNeurowissenschaft im Computerlab FS22"
  },
  {
    "objectID": "slides/02_psychopy.html#section",
    "href": "slides/02_psychopy.html#section",
    "title": "1. Sitzung",
    "section": "",
    "text": "1\n\n\n\nBias RDK Experiment\n\n\n\n\n\n\nNeurowissenschaft im Computerlab FS22"
  },
  {
    "objectID": "slides/02_psychopy.html#bias-rdk-experiment",
    "href": "slides/02_psychopy.html#bias-rdk-experiment",
    "title": "2. Sitzung",
    "section": "Bias RDK Experiment",
    "text": "Bias RDK Experiment\n\n\n\nRandom-dot motion direction-discrimination task\nInside/outside scanner (timing)\nBias: cue (probability left/right/unbiased)\nFixation cross\nRDK: 3x3 pixels, coherence\n40 bias trials, 40 neutral trials\n32 valid, 8 invalid trials"
  },
  {
    "objectID": "slides/02_psychopy.html#psychopy",
    "href": "slides/02_psychopy.html#psychopy",
    "title": "2. Sitzung",
    "section": "PsychoPy",
    "text": "PsychoPy\n\n\n\nPsychoPy Website\nRessourcen\nWalk-through: Builder\nDiskussionsforum\nKapitel: Verhaltensexperiment mit PsychoPy"
  },
  {
    "objectID": "slides/02_psychopy.html#pavlovia",
    "href": "slides/02_psychopy.html#pavlovia",
    "title": "2. Sitzung",
    "section": "Pavlovia",
    "text": "Pavlovia\n\nPavlovia:\n\n\nPavlovia is a place for the wide community of researchers in the behavioural sciences to run, share, and explore experiments online.\n\n\nExperimente suchen.\nZum Beispiel ChoiceRTT ausprobieren und den Code anschauen."
  },
  {
    "objectID": "slides/02_psychopy.html#understanding-your-computer",
    "href": "slides/02_psychopy.html#understanding-your-computer",
    "title": "2. Sitzung",
    "section": "Understanding your Computer",
    "text": "Understanding your Computer\n\nRefresh rate: 60 Hz. Ein Frame dauert 1/60 Sekunde, oder 16.667 ms.\n\nfrom psychopy import visual\n\nwin = visual.Window()\nwin.getActualFrameRate()\n\nKeyboard timing: Variabilit√§t ~15 ms.\nScreen refresh f√§ngt oben an und endet (~10 ms sp√§ter) unten."
  },
  {
    "objectID": "slides/02_psychopy.html#probieren-sie-es-selber",
    "href": "slides/02_psychopy.html#probieren-sie-es-selber",
    "title": "2. Sitzung",
    "section": "Probieren Sie es selber!",
    "text": "Probieren Sie es selber!\n\nVersuchen Sie selber, Teile des Experiments in PsychoPy zu implementieren\n\n\nWenn Sie eine Starthilfe ben√∂tigen, downloaden Sie ein Beipiel: üëâ Practice Trials\nEine Einf√ºhrung finden Sie hier: üëâ Verhaltensexperiment mit PsychoPy\n\n\n\n\nNeurowissenschaft im Computerlab FS22"
  },
  {
    "objectID": "slides/03_import_and_process_data.html#set-up-rrstudio",
    "href": "slides/03_import_and_process_data.html#set-up-rrstudio",
    "title": "3. Sitzung",
    "section": "Set up R/RStudio",
    "text": "Set up R/RStudio\n\n\nüëâ Download R\nüëâ Download RStudio\n\n\nRStudio √∂ffnen\nRStudio einrichten\nPackages installieren\n\ninstall.packages(\"tidyverse\")"
  },
  {
    "objectID": "slides/03_import_and_process_data.html#r-kenntnisse",
    "href": "slides/03_import_and_process_data.html#r-kenntnisse",
    "title": "3. Sitzung",
    "section": "R Kenntnisse",
    "text": "R Kenntnisse\n\n\nüëâ Einf√ºhrung in R\n\nEinf√ºhrung in RStudio\nR Sprache\nControl flow / Funktionen\nDaten importieren / tidy data / visualisieren\nDeskriptive Statistik ]\n\n\nüëâ Data Skills for Reproducible Research\n\nReproducible Workflows\nData visualization\nData wrangling\nIteration & Functions"
  },
  {
    "objectID": "slides/03_import_and_process_data.html#datensatz-importieren",
    "href": "slides/03_import_and_process_data.html#datensatz-importieren",
    "title": "3. Sitzung",
    "section": "Datensatz importieren",
    "text": "Datensatz importieren\nüëâ Download Rstudio Projekt\n\nZZ_rdk-discrimination_2022_Mar_07_1403 aus dem testdata Ordner importieren.\nPractice Trials l√∂schen.\nVariablen ausw√§hlen und umbennen.\n\n    - Trial Index\n    - ID\n    - Cue\n    - Direction\n    - Response / RT\n\nAntworten rekodieren."
  },
  {
    "objectID": "slides/03_import_and_process_data.html#mehrere-datens√§tze-importieren",
    "href": "slides/03_import_and_process_data.html#mehrere-datens√§tze-importieren",
    "title": "3. Sitzung",
    "section": "Mehrere Datens√§tze importieren",
    "text": "Mehrere Datens√§tze importieren\n\n\n\nAlle .csv Files aus dem data Ordner importieren.\nDieselben Schritte wie oben auf alle Datens√§tze anwenden."
  },
  {
    "objectID": "slides/03_import_and_process_data.html#anzahl-korrekter-antworten",
    "href": "slides/03_import_and_process_data.html#anzahl-korrekter-antworten",
    "title": "3. Sitzung",
    "section": "Anzahl korrekter Antworten",
    "text": "Anzahl korrekter Antworten\n\nAccuracy pro Person und pro Bedingung berechnen.\nBedingungen:\n\n   - valid\n   - invalid\n   - neutral"
  },
  {
    "objectID": "slides/03_import_and_process_data.html#probieren-sie-es-selber",
    "href": "slides/03_import_and_process_data.html#probieren-sie-es-selber",
    "title": "3. Sitzung",
    "section": "Probieren Sie es selber!",
    "text": "Probieren Sie es selber!\n\nLearning by doing! Expertise in R erreicht man nur, wenn man selber ausprobiert.\n\n\nKapitel Daten importieren bearbeiten.\nFragen stellen.\nDaten mit esquisse visualisieren:\n\ninstall.packages(\"esquisse\")\nlibrary(esquisse)\nesquisser()\n\n\n\nNeurowissenschaft im Computerlab FS22"
  }
]